{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244ac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdefc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "from SourceCodeTools.models.training_config import get_config, save_config, load_config\n",
    "from SourceCodeTools.code.data.dataset.Dataset import SourceGraphDataset, filter_dst_by_freq\n",
    "from SourceCodeTools.models.graph.train.sampling_multitask2 import training_procedure, SamplingMultitaskTrainer\n",
    "from SourceCodeTools.models.graph.train.objectives.NodeClassificationObjective import NodeClassifierObjective\n",
    "from SourceCodeTools.models.graph.train.objectives.SubgraphClassifierObjective import SubgraphAbstractObjective, \\\n",
    "    SubgraphClassifierObjective, SubgraphEmbeddingObjective\n",
    "from SourceCodeTools.models.graph.train.utils import get_name, get_model_base\n",
    "from SourceCodeTools.models.graph import RGGAN\n",
    "from SourceCodeTools.tabular.common import compact_property\n",
    "from SourceCodeTools.code.data.file_utils import unpersist\n",
    "# from SourceCodeTools.models.graph.train.objectives.SCAAClassifierObjetive import SCAAClassifierObjective\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4becf482",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare parameters and options\n",
    "\n",
    "Full list of options that can be added can be found in `SourceCodeTools/models/training_options.py`. They are ment to be used as arguments for cli trainer. Trainer script can be found in `SourceCodeTools/scripts/train.py`.\n",
    "\n",
    "For the task of subgraph classification the important options are:\n",
    "- `subgraph_partition` is path to subgraph-based train/val/test sets. Storead as Dataframe with subgraph id and partition mask\n",
    "- `subgraph_id_column` is a column is `common_edges` file that stores subgraph id.\n",
    "- For variable misuse task (same will apply to authorship attribution) subgraphs are created for individual functions (files for SCAA). The label is stored in `common_filecontent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5dc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "\n",
    "from SourceCodeTools.models.graph.train.objectives.SubgraphClassifierObjective import SubgraphClassifierObjective\n",
    "\n",
    "\n",
    "class PoolingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, k, shape=1):\n",
    "        super().__init__()\n",
    "        self.learnable_vector = torch.nn.Parameter(torch.randn(shape))\n",
    "        self.learnable_vector.requires_grad = True\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = torch.norm(self.learnable_vector)\n",
    "        y = torch.mm(x, self.learnable_vector)/length\n",
    "        idx = torch.topk(y, self.k)\n",
    "        x_part = x[idx, :]\n",
    "        return torch.mul(x_part, torch.transpose(y))\n",
    "\n",
    "\n",
    "class SCAAClassifierObjective(SubgraphClassifierObjective):\n",
    "\n",
    "    def __init__(\n",
    "            self, name, graph_model, node_embedder, nodes, data_loading_func, device,\n",
    "            sampling_neighbourhood_size, batch_size,\n",
    "            tokenizer_path=None, target_emb_size=None, link_predictor_type=\"inner_prod\",\n",
    "            masker = None, measure_scores=False, dilate_scores=1,\n",
    "            early_stopping=False, early_stopping_tolerance=20, nn_index=\"brute\",\n",
    "            ns_groups=None, subgraph_mapping=None, subgraph_partition=None\n",
    "        ):\n",
    "        SubgraphClassifierObjective.__init__(self,\n",
    "            name, graph_model, node_embedder, nodes, data_loading_func, device,\n",
    "            sampling_neighbourhood_size, batch_size,\n",
    "            tokenizer_path, target_emb_size, link_predictor_type,\n",
    "            masker, measure_scores, dilate_scores, early_stopping, early_stopping_tolerance, nn_index,\n",
    "            ns_groups, subgraph_mapping, subgraph_partition\n",
    "        )\n",
    "        self.pooler = PoolingLayer(50, (1, 128))\n",
    "        \n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return chain(self.classifier.parameters(), self.pooler.parameters())\n",
    "\n",
    "    def custom_state_dict(self):\n",
    "        state_dict = OrderedDict()\n",
    "        for k, v in self.classifier.state_dict().items():\n",
    "            state_dict[f\"classifier.{k}\"] = v\n",
    "        for k, v in self.pooler.state_dict().items():\n",
    "            state_dict[f\"pooler.{k}\"] = v\n",
    "        return state_dict\n",
    "\n",
    "    def custom_load_state_dict(self, state_dicts):\n",
    "        self.classifier.load_state_dict(\n",
    "            self.get_prefix(\"classifier\", state_dicts)\n",
    "        )\n",
    "        self.pooler.load_state_dict(\n",
    "            self.get_prefix(\"pooler\", state_dicts)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5637f70e-b8fd-4a9f-9956-d60a61bd2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"examples/sentencepiece_bpe.model\"\n",
    "\n",
    "data_path = \"examples/scaa\"\n",
    "subgraph_partition = join(data_path, \"subgraph_partition.json.bz2\")\n",
    "filecontent_path = join(data_path, \"common_filecontent.json.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404565f5-09a3-4535-ba51-8533491f7c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id.1</th>\n",
       "      <th>filecontent</th>\n",
       "      <th>user</th>\n",
       "      <th>task</th>\n",
       "      <th>year</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489</td>\n",
       "      <td>489</td>\n",
       "      <td>\"\"\"\\n   Author : thekushalghosh\\n   Team   : C...</td>\n",
       "      <td>thekushalghosh</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>thekushalghosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "      <td>T=int(input())\\nimport math\\nfor i in range(T)...</td>\n",
       "      <td>shubhi_</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>shubhi_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310</td>\n",
       "      <td>310</td>\n",
       "      <td>T,B=[int(x) for x in input().split()]\\nfor x i...</td>\n",
       "      <td>briangodwinlim</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>briangodwinlim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>from __future__ import division, print_functio...</td>\n",
       "      <td>Itachi_uchiha</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>Itachi_uchiha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "      <td>import sys\\n\\n\\ndef main():\\n   cases = int(in...</td>\n",
       "      <td>erdnase</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>erdnase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>def extractLine():\\n   line = input()\\n   arr ...</td>\n",
       "      <td>DavidEdey</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>DavidEdey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>num_tests = int(input())\\n\\ndef sol(pairs):\\n ...</td>\n",
       "      <td>KimJohnWu</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>KimJohnWu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>import sys\\n\\ndef printsmallpath(n): # n &lt;= 50...</td>\n",
       "      <td>spelvin</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>spelvin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>def process_matrix(matrix):\\n   N = len(matrix...</td>\n",
       "      <td>luctchak</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>luctchak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>import sys\\nimport copy\\nfrom math import *\\nf...</td>\n",
       "      <td>Pedastrian</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>Pedastrian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  id.1                                        filecontent  \\\n",
       "0    489   489  \"\"\"\\n   Author : thekushalghosh\\n   Team   : C...   \n",
       "1    474   474  T=int(input())\\nimport math\\nfor i in range(T)...   \n",
       "2    310   310  T,B=[int(x) for x in input().split()]\\nfor x i...   \n",
       "3     80    80  from __future__ import division, print_functio...   \n",
       "4    374   374  import sys\\n\\n\\ndef main():\\n   cases = int(in...   \n",
       "..   ...   ...                                                ...   \n",
       "508   48    48  def extractLine():\\n   line = input()\\n   arr ...   \n",
       "509  108   108  num_tests = int(input())\\n\\ndef sol(pairs):\\n ...   \n",
       "510  484   484  import sys\\n\\ndef printsmallpath(n): # n <= 50...   \n",
       "511  406   406  def process_matrix(matrix):\\n   N = len(matrix...   \n",
       "512  152   152  import sys\\nimport copy\\nfrom math import *\\nf...   \n",
       "\n",
       "               user  task  year         package  \n",
       "0    thekushalghosh     3  2020  thekushalghosh  \n",
       "1           shubhi_     6  2020         shubhi_  \n",
       "2    briangodwinlim     4  2020  briangodwinlim  \n",
       "3     Itachi_uchiha     8  2020   Itachi_uchiha  \n",
       "4           erdnase     5  2020         erdnase  \n",
       "..              ...   ...   ...             ...  \n",
       "508       DavidEdey     3  2020       DavidEdey  \n",
       "509       KimJohnWu     0  2020       KimJohnWu  \n",
       "510         spelvin     7  2020         spelvin  \n",
       "511        luctchak     1  2020        luctchak  \n",
       "512      Pedastrian     8  2020      Pedastrian  \n",
       "\n",
       "[513 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpersist(filecontent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09b740a-eaaf-4fac-a73f-0bd9bb671f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>source_node_id</th>\n",
       "      <th>target_node_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>mentioned_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subword</td>\n",
       "      <td>68048</td>\n",
       "      <td>49684</td>\n",
       "      <td>489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>49684</td>\n",
       "      <td>32062</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>name_rev</td>\n",
       "      <td>32062</td>\n",
       "      <td>49684</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>names</td>\n",
       "      <td>32062</td>\n",
       "      <td>75398</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>names_rev</td>\n",
       "      <td>75398</td>\n",
       "      <td>32062</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>subword</td>\n",
       "      <td>48908</td>\n",
       "      <td>19829</td>\n",
       "      <td>489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>name</td>\n",
       "      <td>19829</td>\n",
       "      <td>70699</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>name_rev</td>\n",
       "      <td>70699</td>\n",
       "      <td>19829</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>names</td>\n",
       "      <td>70699</td>\n",
       "      <td>75398</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>names_rev</td>\n",
       "      <td>75398</td>\n",
       "      <td>70699</td>\n",
       "      <td>489</td>\n",
       "      <td>20349.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       type  source_node_id  target_node_id  file_id  mentioned_in\n",
       "0   0    subword           68048           49684      489           NaN\n",
       "1   1       name           49684           32062      489       20349.0\n",
       "2   2   name_rev           32062           49684      489       20349.0\n",
       "3   3      names           32062           75398      489       20349.0\n",
       "4   4  names_rev           75398           32062      489       20349.0\n",
       "5   5    subword           48908           19829      489           NaN\n",
       "6   6       name           19829           70699      489       20349.0\n",
       "7   7   name_rev           70699           19829      489       20349.0\n",
       "8   8      names           70699           75398      489       20349.0\n",
       "9   9  names_rev           75398           70699      489       20349.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpersist(join(data_path, \"common_edges.json.bz2\"), nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38f83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(\n",
    "    subgraph_id_column=\"file_id\",\n",
    "    data_path=data_path,\n",
    "    model_output_dir=data_path,\n",
    "    subgraph_partition=subgraph_partition,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    objectives=\"subgraph_clf\",\n",
    "    epochs=1000,\n",
    "    elem_emb_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf61e1a2-2a2b-4688-b6b6-4ad3c22b22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_config(config, \"var_misuse_tiny.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc7b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': {'data_path': 'scaa',\n",
       "  'train_frac': 0.9,\n",
       "  'filter_edges': None,\n",
       "  'min_count_for_objectives': 5,\n",
       "  'self_loops': False,\n",
       "  'use_node_types': False,\n",
       "  'use_edge_types': False,\n",
       "  'no_global_edges': False,\n",
       "  'remove_reverse': False,\n",
       "  'custom_reverse': None,\n",
       "  'restricted_id_pool': None,\n",
       "  'random_seed': None,\n",
       "  'subgraph_id_column': 'file_id',\n",
       "  'subgraph_partition': 'scaa/subgraph_partition.json.bz2'},\n",
       " 'TRAINING': {'model_output_dir': 'scaa',\n",
       "  'pretrained': None,\n",
       "  'pretraining_phase': 0,\n",
       "  'sampling_neighbourhood_size': 10,\n",
       "  'neg_sampling_factor': 3,\n",
       "  'use_layer_scheduling': False,\n",
       "  'schedule_layers_every': 10,\n",
       "  'elem_emb_size': 50,\n",
       "  'embedding_table_size': 200000,\n",
       "  'epochs': 1000,\n",
       "  'batch_size': 128,\n",
       "  'learning_rate': 0.001,\n",
       "  'objectives': 'subgraph_clf',\n",
       "  'save_each_epoch': False,\n",
       "  'save_checkpoints': True,\n",
       "  'early_stopping': False,\n",
       "  'early_stopping_tolerance': 20,\n",
       "  'force_w2v_ns': False,\n",
       "  'use_ns_groups': False,\n",
       "  'nn_index': 'brute',\n",
       "  'metric': 'inner_prod',\n",
       "  'measure_scores': False,\n",
       "  'dilate_scores': 200,\n",
       "  'gpu': -1,\n",
       "  'external_dataset': None,\n",
       "  'restore_state': False},\n",
       " 'MODEL': {'node_emb_size': 100,\n",
       "  'h_dim': 100,\n",
       "  'n_layers': 5,\n",
       "  'use_self_loop': True,\n",
       "  'use_gcn_checkpoint': False,\n",
       "  'use_att_checkpoint': False,\n",
       "  'use_gru_checkpoint': False,\n",
       "  'num_bases': 10,\n",
       "  'dropout': 0.0,\n",
       "  'activation': 'tanh'},\n",
       " 'TOKENIZER': {'tokenizer_path': 'sentencepiece_bpe.model'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a2528",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ce29fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/workspace/method-embedding/SourceCodeTools/code/data/dataset/Dataset.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.nodes = self.nodes.append(new_nodes, ignore_index=True)\n",
      "/home/alina/workspace/method-embedding/SourceCodeTools/code/data/dataset/Dataset.py:130: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.edges = self.edges.append(new_edges, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = SourceGraphDataset(\n",
    "    **{**config[\"DATASET\"], **config[\"TOKENIZER\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d41bf",
   "metadata": {},
   "source": [
    "# Declare target loading function (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c279f43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "    filecontent = unpersist(filecontent_path)\n",
    "    return filecontent[[\"id\", \"user\"]].rename({\"id\": \"src\", \"user\": \"dst\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac27d90",
   "metadata": {},
   "source": [
    "One or several objectives could be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67605a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(SamplingMultitaskTrainer):\n",
    "    def create_objectives(self, dataset, tokenizer_path):\n",
    "        self.objectives = nn.ModuleList()\n",
    "        \n",
    "        self.objectives.append(\n",
    "            self._create_subgraph_objective(\n",
    "                objective_name=\"VariableMisuseClf\",\n",
    "                objective_class=SCAAClassifierObjective,\n",
    "                dataset=dataset,\n",
    "                tokenizer_path=tokenizer_path,\n",
    "                labels_fn=load_labels,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393251c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow listening on http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "# %tensorboard --logdir data\n",
    "from tensorboard import program\n",
    "\n",
    "tracking_address = './scaa/' # the path of your log file.\n",
    "\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, '--logdir', tracking_address])\n",
    "url = tb.launch()\n",
    "print(f\"Tensorflow listening on {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369ed1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes 80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x100 and 50x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/alina/workspace/scaa/method-embedding/examples/Subgraph Classification.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=0'>1</a>\u001b[0m training_procedure(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=1'>2</a>\u001b[0m     dataset, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=2'>3</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49mRGGAN, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=3'>4</a>\u001b[0m     model_params\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mMODEL\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=4'>5</a>\u001b[0m     trainer_params\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mTRAINING\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=5'>6</a>\u001b[0m     model_base_path\u001b[39m=\u001b[39;49mget_model_base(config[\u001b[39m\"\u001b[39;49m\u001b[39mTRAINING\u001b[39;49m\u001b[39m\"\u001b[39;49m], get_name(RGGAN, \u001b[39mstr\u001b[39;49m(datetime\u001b[39m.\u001b[39;49mnow()))),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=6'>7</a>\u001b[0m     trainer\u001b[39m=\u001b[39;49mTrainer\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alina/workspace/scaa/method-embedding/examples/Subgraph%20Classification.ipynb#ch0000017?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py:780\u001b[0m, in \u001b[0;36mtraining_procedure\u001b[0;34m(dataset, model_name, model_params, trainer_params, model_base_path, tokenizer_path, trainer, load_external_dataset)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=766'>767</a>\u001b[0m trainer \u001b[39m=\u001b[39m trainer(\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=767'>768</a>\u001b[0m     dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=768'>769</a>\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=775'>776</a>\u001b[0m     load_external_dataset\u001b[39m=\u001b[39mload_external_dataset\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=776'>777</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=778'>779</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=779'>780</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_all()\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=780'>781</a>\u001b[0m \u001b[39m# except KeyboardInterrupt:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=781'>782</a>\u001b[0m \u001b[39m#     logging.info(\"Training interrupted\")\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=782'>783</a>\u001b[0m \u001b[39m# except EarlyStopping:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=783'>784</a>\u001b[0m \u001b[39m#     logging.info(\"Early stopping triggered\")\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=784'>785</a>\u001b[0m \u001b[39m# except Exception as e:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=785'>786</a>\u001b[0m \u001b[39m#     print(\"There was an exception\", e)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=787'>788</a>\u001b[0m trainer\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py:502\u001b[0m, in \u001b[0;36mSamplingMultitaskTrainer.train_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=498'>499</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=500'>501</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=501'>502</a>\u001b[0m loss, acc \u001b[39m=\u001b[39m objective(\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=502'>503</a>\u001b[0m     input_nodes, seeds, blocks, train_embeddings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfinetune,\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=503'>504</a>\u001b[0m     neg_sampling_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mw2v\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer_params[\u001b[39m\"\u001b[39;49m\u001b[39mforce_w2v_ns\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=504'>505</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=506'>507</a>\u001b[0m loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjectives)  \u001b[39m# assumes the same batch size for all objectives\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/sampling_multitask2.py?line=507'>508</a>\u001b[0m loss_accum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py:211\u001b[0m, in \u001b[0;36mSubgraphAbstractObjective.forward\u001b[0;34m(self, input_nodes, seeds, blocks, train_embeddings, neg_sampling_strategy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=203'>204</a>\u001b[0m graph_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_embeddings(input_nodes, blocks, train_embeddings, masked\u001b[39m=\u001b[39mmasked, subgraph_masks\u001b[39m=\u001b[39msubgraph_masks)\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=204'>205</a>\u001b[0m subgraph_embs_, element_embs_, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_prediction(\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=205'>206</a>\u001b[0m     graph_emb, seeds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_embedding_fn, negative_factor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_factor,\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=206'>207</a>\u001b[0m     neg_sampling_strategy\u001b[39m=\u001b[39mneg_sampling_strategy,\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=207'>208</a>\u001b[0m     train_embeddings\u001b[39m=\u001b[39mtrain_embeddings\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=208'>209</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=210'>211</a>\u001b[0m acc, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_acc_loss(subgraph_embs_, element_embs_, labels)\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/SubgraphClassifierObjective.py?line=212'>213</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss, acc\n",
      "File \u001b[0;32m~/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py:41\u001b[0m, in \u001b[0;36mNodeClassifierObjective.compute_acc_loss\u001b[0;34m(self, graph_emb, element_emb, labels, return_logits)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=39'>40</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_acc_loss\u001b[39m(\u001b[39mself\u001b[39m, graph_emb, element_emb, labels, return_logits\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=40'>41</a>\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier(graph_emb)\n\u001b[1;32m     <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=42'>43</a>\u001b[0m     loss_fct \u001b[39m=\u001b[39m CrossEntropyLoss(ignore_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=43'>44</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fct(logits\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, logits\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)),\n\u001b[1;32m     <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=44'>45</a>\u001b[0m                     labels\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py:158\u001b[0m, in \u001b[0;36mNodeClassifier.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=157'>158</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_a(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1(x))\n\u001b[1;32m    <a href='file:///home/alina/workspace/method-embedding/SourceCodeTools/models/graph/train/objectives/NodeClassificationObjective.py?line=158'>159</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=94'>95</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/functional.py?line=1844'>1845</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/functional.py?line=1845'>1846</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> <a href='file:///home/alina/.local/lib/python3.9/site-packages/torch/nn/functional.py?line=1846'>1847</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x100 and 50x100)"
     ]
    }
   ],
   "source": [
    "training_procedure(\n",
    "    dataset, \n",
    "    model_name=RGGAN, \n",
    "    model_params=config[\"MODEL\"],\n",
    "    trainer_params=config[\"TRAINING\"],\n",
    "    model_base_path=get_model_base(config[\"TRAINING\"], get_name(RGGAN, str(datetime.now()))),\n",
    "    trainer=Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cf5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python [conda env:SourceCodeTools]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
