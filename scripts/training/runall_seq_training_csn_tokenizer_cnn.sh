# for i in 1 2 3 4 5; do
python ~/method-embedding-main/SourceCodeTools/nlp/entity/type_prediction.py --data_path ../annotations_dataset_no_default_arg_replaced.jsonl --graph_emb_path embeddings.pkl --word_emb_path ~/data/codesearchnet_codebert_proper_10_768/codesearchnet_10_768_cubert_tok_proper.pkl type_annotation --random_seed 42 --epochs 300 --batch_size 8 --max_seq_len 512 --learning_rate 0.0001 --learning_rate_decay 0.99 --trials 1 --type_ann_edges ../type_annotations.bz2 --gpu 1
python ~/method-embedding-main/SourceCodeTools/nlp/entity/type_prediction.py --data_path ../annotations_dataset_no_default_arg_replaced.jsonl --graph_emb_path embeddings.pkl --word_emb_path ~/data/codesearchnet_codebert_proper_10_768/codesearchnet_10_768_cubert_tok_proper.pkl type_annotation --random_seed 42 --epochs 300 --batch_size 8 --max_seq_len 512 --learning_rate 0.0001 --learning_rate_decay 0.99 --trials 1 --type_ann_edges ../type_annotations.bz2 --gpu 1 --restrict_allowed
python ~/method-embedding-main/SourceCodeTools/nlp/entity/type_prediction.py --data_path ../annotations_dataset_no_default_arg_replaced.jsonl --graph_emb_path embeddings.pkl --word_emb_path ~/data/codesearchnet_codebert_proper_10_768/codesearchnet_10_768_cubert_tok_proper.pkl type_annotation --random_seed 42 --epochs 300 --batch_size 8 --max_seq_len 512 --learning_rate 0.0001 --learning_rate_decay 0.99 --trials 1 --type_ann_edges ../type_annotations.bz2 --gpu 1 --restrict_allowed --no_localization
python ~/method-embedding-main/SourceCodeTools/nlp/entity/type_prediction.py --data_path ../annotations_dataset_no_default_arg_replaced.jsonl --graph_emb_path embeddings.pkl --word_emb_path ~/data/codesearchnet_codebert_proper_10_768/codesearchnet_10_768_cubert_tok_proper.pkl type_annotation --random_seed 42 --epochs 300 --batch_size 8 --max_seq_len 512 --learning_rate 0.0001 --learning_rate_decay 0.99 --trials 1 --type_ann_edges ../type_annotations.bz2 --gpu 1 --no_localization
# done