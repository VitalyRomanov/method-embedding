{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244ac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdefc65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from SourceCodeTools.models.training_config import load_config\n",
    "from SourceCodeTools.code.data.dataset.Dataset import SourceGraphDataset\n",
    "from SourceCodeTools.models.graph.train.sampling_multitask2 import SamplingMultitaskTrainer, \\\n",
    "    select_device\n",
    "from SourceCodeTools.models.graph.train.objectives.NodeClassificationObjective import NodeClassifierObjective, \\\n",
    "    ClassifierTargetMapper\n",
    "from SourceCodeTools.models.graph import RGGAN, RGCN\n",
    "\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4becf482",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare parameters and options\n",
    "\n",
    "Full list of options that can be added can be found in `SourceCodeTools/models/training_options.py`. They are ment to be used as arguments for cli trainer. Trainer script can be found in `SourceCodeTools/scripts/train.py`.\n",
    "\n",
    "For the task of subgraph classification the important options are:\n",
    "- `subgraph_partition` is path to subgraph-based train/val/test sets. Storead as Dataframe with subgraph id and partition mask\n",
    "- `subgraph_id_column` is a column is `common_edges` file that stores subgraph id.\n",
    "- For variable misuse task (same will apply to authorship attribution) subgraphs are created for individual functions (files for SCAA). The label is stored in `common_filecontent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5637f70e-b8fd-4a9f-9956-d60a61bd2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"sentencepiece_bpe.model\"\n",
    "\n",
    "data_path = \"v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast\"\n",
    "partition = join(data_path, \"partition_type_prediction.json.bz2\")\n",
    "type_annotations_path = join(data_path, \"type_annotations.json.bz2\")\n",
    "\n",
    "# checkpoint_path = \"v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/RGCN-2023-01-29-18-19-15-468135\"\n",
    "# checkpoint_path = \"v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/RGCN-2023-01-30-19-47-28-861157\"\n",
    "# checkpoint_path = \"v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/RGCN-2023-01-30-14-08-35-988001_without_subwords\"\n",
    "checkpoint_path = \"v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/RGCN-2023-01-31-17-58-43-579368_subword_masking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38f83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = get_config(\n",
    "#     data_path=data_path,\n",
    "#     model_output_dir=data_path,\n",
    "#     partition=partition,\n",
    "#     tokenizer_path=tokenizer_path,\n",
    "#     objectives=\"node_clf\",\n",
    "#     batch_size=1\n",
    "# )\n",
    "\n",
    "config = load_config(join(checkpoint_path, \"config.yaml\"))\n",
    "config[\"TRAINING\"][\"restore_state\"] = True\n",
    "config[\"TRAINING\"][\"batch_size\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b02604b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'DATASET': {'custom_reverse': None,\n  'data_path': '/Users/LTV/Downloads/NitroShare/v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/',\n  'filter_edges': None,\n  'min_count_for_objectives': 3,\n  'no_global_edges': True,\n  'partition': '/Users/LTV/Downloads/NitroShare/v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/partition_type_prediction.json.bz2',\n  'random_seed': 42,\n  'remove_reverse': False,\n  'restricted_id_pool': None,\n  'self_loops': False,\n  'subgraph_id_column': None,\n  'subgraph_partition': None,\n  'train_frac': 0.9,\n  'use_edge_types': True,\n  'use_node_types': False},\n 'MODEL': {'activation': 'relu',\n  'dropout': 0.0,\n  'h_dim': None,\n  'n_layers': 5,\n  'node_emb_size': 100,\n  'num_bases': 10,\n  'use_att_checkpoint': False,\n  'use_gcn_checkpoint': False,\n  'use_gru_checkpoint': False,\n  'use_self_loop': True},\n 'TOKENIZER': {'tokenizer_path': '/Users/LTV/Dropbox (Personal)/sentencepiece_bpe.model'},\n 'TRAINING': {'batch_size': 1,\n  'dilate_scores': 200,\n  'early_stopping': False,\n  'early_stopping_tolerance': 20,\n  'elem_emb_size': 100,\n  'embedding_table_size': 1000000,\n  'epochs': 300,\n  'etypes': ['defines_',\n   'uses_',\n   'imports_',\n   'calls_',\n   'uses_type_',\n   'inheritance_',\n   'defined_in_',\n   'used_by_',\n   'imported_by_',\n   'called_by_',\n   'type_used_by_',\n   'inherited_by_',\n   'subword_',\n   'module_',\n   'global_mention_',\n   'module_rev_',\n   'name_',\n   'name_rev_',\n   'names_',\n   'names_rev_',\n   'defined_in_module_',\n   'defined_in_module_rev_',\n   'next_',\n   'prev_',\n   'value_',\n   'value_rev_',\n   'attr_',\n   'func_',\n   'func_rev_',\n   'slice_',\n   'slice_rev_',\n   'args_',\n   'args_rev_',\n   'arg_',\n   'arg_rev_',\n   'left_',\n   'left_rev_',\n   'ops_',\n   'comparators_',\n   'values_',\n   'values_rev_',\n   'op_',\n   'test_',\n   'test_rev_',\n   'elts_',\n   'elts_rev_',\n   'right_',\n   'right_rev_',\n   'targets_',\n   'targets_rev_',\n   'executed_if_true_',\n   'executed_if_true_rev_',\n   'exc_',\n   'exc_rev_',\n   'defined_in_function_',\n   'defined_in_function_rev_',\n   'function_name_',\n   'function_name_rev_',\n   'keywords_',\n   'keywords_rev_',\n   'kwarg_',\n   'kwarg_rev_',\n   'executed_if_false_',\n   'executed_if_false_rev_',\n   'target_',\n   'target_rev_',\n   'iter_',\n   'iter_rev_',\n   'executed_in_for_',\n   'executed_in_for_rev_',\n   'comparators_rev_',\n   'executed_in_try_',\n   'executed_in_try_rev_',\n   'type_',\n   'type_rev_',\n   'executed_with_try_handler_',\n   'executed_with_try_handler_rev_',\n   'operand_',\n   'operand_rev_',\n   'elt_',\n   'elt_rev_',\n   'generators_',\n   'generators_rev_',\n   'defined_in_class_',\n   'defined_in_class_rev_',\n   'class_name_',\n   'class_name_rev_',\n   'decorator_list_',\n   'decorator_list_rev_',\n   'if_true_',\n   'if_true_rev_',\n   'if_false_',\n   'if_false_rev_',\n   'lower_',\n   'upper_',\n   'upper_rev_',\n   'control_flow_',\n   'lower_rev_',\n   'executed_while_true_',\n   'executed_while_true_rev_',\n   'asname_',\n   'asname_rev_',\n   'keys_',\n   'vararg_',\n   'vararg_rev_',\n   'executed_in_try_final_',\n   'executed_in_try_final_rev_',\n   'ifs_',\n   'ifs_rev_',\n   'context_expr_',\n   'context_expr_rev_',\n   'optional_vars_',\n   'optional_vars_rev_',\n   'items_',\n   'items_rev_',\n   'executed_inside_with_',\n   'executed_inside_with_rev_',\n   'lambda_',\n   'lambda_rev_',\n   'key_',\n   'key_rev_',\n   'executed_in_try_else_',\n   'executed_in_try_else_rev_',\n   'msg_',\n   'msg_rev_',\n   'keys_rev_',\n   'step_',\n   'step_rev_',\n   'executed_in_for_orelse_',\n   'executed_in_for_orelse_rev_',\n   'dims_',\n   'dims_rev_',\n   'kwonlyargs_',\n   'kwonlyargs_rev_',\n   'cause_',\n   'cause_rev_'],\n  'external_dataset': None,\n  'force_w2v_ns': True,\n  'gpu': -1,\n  'inference_ids_path': None,\n  'learning_rate': 0.001,\n  'measure_scores': False,\n  'metric': 'inner_prod',\n  'model': 'RGCN',\n  'model_output_dir': '/Users/LTV/Downloads/NitroShare/v2_subsample_v4_new_ast2_fixed_distinct_types/with_ast/',\n  'neg_sampling_factor': 1,\n  'nn_index': 'brute',\n  'ntypes': ['node_'],\n  'objectives': ['type_ann_pred'],\n  'pretrained': '/Users/LTV/Downloads/NitroShare/emb_bpe_100_1000000.txt',\n  'pretraining_phase': 0,\n  'restore_state': True,\n  'sampling_neighbourhood_size': 10,\n  'save_checkpoints': True,\n  'save_each_epoch': False,\n  'schedule_layers_every': 10,\n  'skip_final_eval': False,\n  'use_layer_scheduling': False,\n  'use_ns_groups': False}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = SourceGraphDataset(\n",
    "    **{**config[\"DATASET\"], **config[\"TOKENIZER\"]}\n",
    ")\n",
    "ntypes, etypes = dataset.get_graph_types()\n",
    "config[\"TRAINING\"]['ntypes'] = ntypes\n",
    "config[\"TRAINING\"]['etypes'] = etypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "897d41bf",
   "metadata": {},
   "source": [
    "# Declare objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32ef5225-98e9-4e3b-9c1e-a1432a6bb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassifierObjectiveWithSaliency(NodeClassifierObjective):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NodeClassifierObjectiveWithSaliency, self).__init__(**kwargs)\n",
    "\n",
    "    def saliency_for_batch(\n",
    "            self, batch_ind, batch, optimizer\n",
    "    ):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = self(\n",
    "            **batch\n",
    "        )\n",
    "\n",
    "        # collect gradients\n",
    "        outputs.gnn_output.node_embeddings[\"node_\"].retain_grad()\n",
    "        outputs.gnn_output.input_embeddings[\"node_\"].retain_grad()\n",
    "        outputs.loss.backward()\n",
    "\n",
    "        # get input node ids\n",
    "        def get_original_node_ids(block):\n",
    "            return block.srcnodes[\"node_\"].data[\"original_id\"].tolist()\n",
    "\n",
    "        original_node_ids = get_original_node_ids(batch[\"blocks\"][0])\n",
    "        graph_node_ids = get_original_node_ids(batch[\"blocks\"][-1])\n",
    "\n",
    "        # compute saliency scores for nodes\n",
    "        def compute_saliency_score(tensor_):\n",
    "            return tensor_.abs().mean(dim=-1).numpy()\n",
    "\n",
    "        input_node_saliency = compute_saliency_score(\n",
    "            outputs.gnn_output.input_embeddings[\"node_\"].grad.data\n",
    "        )\n",
    "\n",
    "        # retrieve additional information for nodes for display\n",
    "        def get_information_for_nodes(node_ids):\n",
    "            node_info = dataset._graph_storage.database.query(f\"\"\"\n",
    "            select nodes.id, name, string, type_desc as type from nodes\n",
    "            left join node_strings on node_strings.id = nodes.id\n",
    "            left join node_types on node_types.type_id = nodes.type\n",
    "            where nodes.id in ({\",\".join(set(map(str, node_ids)))})\n",
    "            \"\"\")\n",
    "\n",
    "            return {\n",
    "                \"names\": dict(zip(node_info[\"id\"], node_info[\"name\"])),\n",
    "                \"strings\": dict(zip(node_info[\"id\"], node_info[\"string\"])),\n",
    "                \"types\": dict(zip(node_info[\"id\"], node_info[\"type\"]))\n",
    "            }\n",
    "\n",
    "        def get_function_for_node(node_id):\n",
    "            function = dataset._graph_storage.database.query(f\"\"\"\n",
    "            select node_strings.string\n",
    "            from node_hierarchy\n",
    "            join node_strings on node_hierarchy.mentioned_in = node_strings.id\n",
    "            where node_hierarchy.id = {node_id}\n",
    "            \"\"\")\n",
    "\n",
    "            if len(function) == 0:\n",
    "                return None\n",
    "            else:\n",
    "                return function.iloc[0,0]\n",
    "\n",
    "        node_info = get_information_for_nodes(original_node_ids + graph_node_ids)\n",
    "        function_text = get_function_for_node(graph_node_ids[0])\n",
    "\n",
    "        def make_saliency_summary_table(node_ids, saliency, node_info):\n",
    "            # sort input nodes by saliency\n",
    "            id_saliency = sorted(\n",
    "                zip(node_ids, saliency),\n",
    "                key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "\n",
    "            input_nodes_summary = {\n",
    "                \"ids\": list(map(lambda x: x[0], id_saliency)),\n",
    "                \"score\": list(map(lambda x: x[1], id_saliency)),\n",
    "                \"name\": list(map(lambda x: node_info[\"names\"][x[0]], id_saliency)),\n",
    "                \"type\": list(map(lambda x: node_info[\"types\"][x[0]], id_saliency)),\n",
    "                \"string\": list(map(lambda x: node_info[\"strings\"].get(x[0], pd.NA), id_saliency)),\n",
    "            }\n",
    "\n",
    "            return pd.DataFrame(input_nodes_summary)\n",
    "\n",
    "        input_node_saliency_summary = make_saliency_summary_table(original_node_ids, input_node_saliency, node_info)\n",
    "\n",
    "        decoder = self.dataloader.label_encoder.get_original_targets()\n",
    "        # there is only one item in graph_node_ids\n",
    "        print(\"Function:\\n\", function_text)\n",
    "        print(\"Investigating: \", node_info[\"names\"][graph_node_ids[0]])\n",
    "\n",
    "        prediction = outputs.prediction[0][0]\n",
    "        labels = outputs.labels[0][0]\n",
    "\n",
    "        # print top 3 predicted classes\n",
    "        print(f\"Top 3 predicted classes:\")\n",
    "        for ind, c in enumerate(torch.argsort(prediction, descending=True)):\n",
    "            if ind >= 3:\n",
    "                break\n",
    "            print(f\"{decoder[c.item()]}\\t{prediction[c].item():.4f}\")\n",
    "\n",
    "        # print the true class\n",
    "        print(f\"True class: {decoder[labels.item()]}\")\n",
    "\n",
    "        # print saliency in decreasing order\n",
    "        print(\"Input saliency\")\n",
    "        print(input_node_saliency_summary[[\"ids\", \"score\", \"name\", \"type\"]].head(10).to_string())\n",
    "        print(\"\\n\\n\\n\")\n",
    "\n",
    "    def saliency(self, data_split, optimizer):\n",
    "        for batch_ind, batch in enumerate(tqdm(\n",
    "                self.get_iterator(data_split), total=getattr(self, f\"num_{data_split}_batches\")\n",
    "        )):\n",
    "            self.saliency_for_batch(batch_ind, batch, optimizer)\n",
    "            if batch_ind == 10:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Declare trainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67605a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingMultitaskTrainerWithSaliency(SamplingMultitaskTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def train_step_for_objective(self, step, objective, objective_iterator, longterm_metrics):\n",
    "        batch = next(objective_iterator)\n",
    "\n",
    "        objective_output, scores = objective.make_step(\n",
    "            step, batch, \"train\", longterm_metrics, scorer=None\n",
    "        )\n",
    "\n",
    "        if scores is None:\n",
    "            return None\n",
    "\n",
    "        objective_output[\"loss\"].backward()\n",
    "\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def create_objectives(self, dataset, tokenizer_path):\n",
    "        self.objectives = nn.ModuleList()\n",
    "        \n",
    "        self.objectives.append(\n",
    "            self._create_node_level_objective(\n",
    "                objective_name=\"TypeAnnPrediction\",\n",
    "                objective_class=NodeClassifierObjectiveWithSaliency,\n",
    "                label_loader_class=ClassifierTargetMapper,\n",
    "                dataset=dataset,\n",
    "                labels_fn=dataset.load_type_prediction,\n",
    "                tokenizer_path=tokenizer_path,\n",
    "                masker_fn=dataset.create_subword_masker,\n",
    "                preload_for=\"package\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def saliency(self):\n",
    "        objective = self.objectives[0]\n",
    "        objective.eval()\n",
    "        objective.saliency(\"train\", self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81bd9957",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training_procedure(\n",
    "#     dataset,\n",
    "#     model_name=RGGAN,\n",
    "#     model_params=config[\"MODEL\"],\n",
    "#     trainer_params=config[\"TRAINING\"],\n",
    "#     model_base_path=get_model_base(config[\"TRAINING\"], get_name(RGGAN, str(datetime.now()))),\n",
    "#     trainer=SamplingMultitaskTrainerWithSaliency\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f69fa7fe-0935-4ef1-a084-1c6552a28e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency(\n",
    "        dataset, model_name, model_params, trainer_params, model_base_path,\n",
    "        tokenizer_path=None, trainer=None, load_external_dataset=None\n",
    "):\n",
    "    model_params = copy(model_params)\n",
    "    trainer_params = copy(trainer_params)\n",
    "\n",
    "    if trainer is None:\n",
    "        trainer = SamplingMultitaskTrainer\n",
    "\n",
    "    device = select_device(trainer_params)\n",
    "\n",
    "    trainer_params['model_base_path'] = model_base_path\n",
    "\n",
    "    trainer = trainer(\n",
    "        dataset=dataset,\n",
    "        model_name=model_name,\n",
    "        model_params=model_params,\n",
    "        trainer_params=trainer_params,\n",
    "        restore=trainer_params[\"restore_state\"],\n",
    "        device=device,\n",
    "        pretrained_embeddings_path=trainer_params[\"pretrained\"],\n",
    "        tokenizer_path=tokenizer_path,\n",
    "    )\n",
    "\n",
    "    trainer.saliency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e049d48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter `h_dim` is not provided, setting it to: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1864 [00:06<3:18:22,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def script_for_render_items(docs_json_or_id, render_items: List[RenderItem],\n",
      "                            app_path: Optional[str] = None, absolute_url: Optional[str] = None) -> str:\n",
      "    ''' Render an script for Bokeh render items.\n",
      "    Args:\n",
      "        docs_json_or_id:\n",
      "            can be None\n",
      "\n",
      "        render_items (RenderItems) :\n",
      "            Specific items to render from the document and where\n",
      "\n",
      "        app_path (str, optional) :\n",
      "\n",
      "        absolute_url (Theme, optional) :\n",
      "\n",
      "    Returns:\n",
      "        str\n",
      "    '''\n",
      "    if isinstance(docs_json_or_id, str):\n",
      "        docs_json = \"document.getElementById('%s').textContent\" % docs_json_or_id\n",
      "    else:\n",
      "        # XXX: encodes &, <, > and ', but not \". This is because \" is used a lot in JSON,\n",
      "        # and encoding it would significantly increase size of generated files. Doing so\n",
      "        # is safe, because \" in strings was already encoded by JSON, and the semi-encoded\n",
      "        # JSON string is included in JavaScript in single quotes.\n",
      "        docs_json = serialize_json(docs_json_or_id, pretty=False) # JSON string\n",
      "        docs_json = escape(docs_json, quote=(\"'\",))               # make HTML-safe\n",
      "        docs_json = docs_json.replace(\"\\\\\", \"\\\\\\\\\")               # double encode escapes\n",
      "        docs_json =  \"'\" + docs_json + \"'\"                        # JS string\n",
      "\n",
      "    js = DOC_JS.render(\n",
      "        docs_json=docs_json,\n",
      "        render_items=serialize_json([ item.to_json() for item in render_items ], pretty=False),\n",
      "        app_path=app_path,\n",
      "        absolute_url=absolute_url,\n",
      "    )\n",
      "\n",
      "    if not settings.dev:\n",
      "        js = wrap_in_safely(js)\n",
      "\n",
      "    return wrap_in_onload(js)\n",
      "Investigating:  app_path@FunctionDef_0x16e393f6e0ab895b\n",
      "Predicted class:\n",
      "int\t0.9612\n",
      "Optional\t0.0193\n",
      "bool\t0.0122\n",
      "True class: Optional\n",
      "Input saliency\n",
      "       ids     score                                     name         type\n",
      "0   200366  0.172242               keyword_0x16e393f6e0b81b37      keyword\n",
      "1  1350353  0.064991             arguments_0x16e393f6e0a2b6a8    arguments\n",
      "2  2134397  0.026631                   arg_0x16e393f6e0accbc7          arg\n",
      "3    10219  0.019197  app_path@FunctionDef_0x16e393f6e0ab895b      mention\n",
      "4   745275  0.003319                                 app_path    #keyword#\n",
      "5   648826  0.002071           FunctionDef_0x16e393f6e0ab895b  FunctionDef\n",
      "6   448123  0.001488             Attribute_0x16e393f6e03b3b07    Attribute\n",
      "7  2289065  0.000867                  Call_0x16e393f6e0447a0d         Call\n",
      "8  1793717  0.000595                                     ▁app      subword\n",
      "9  1745199  0.000595                                        _      subword\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1864 [00:06<2:23:07,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def _base64_decode(encoded: Union[bytes, str], encoding: Optional[str] = None) -> Union[bytes, str]:\n",
      "    # base64 lib both takes and returns bytes, we want to work with strings\n",
      "    encoded_as_bytes = codecs.encode(encoded, 'ascii') if isinstance(encoded, str) else encoded\n",
      "    # put the padding back\n",
      "    mod = len(encoded_as_bytes) % 4\n",
      "    if mod != 0:\n",
      "        encoded_as_bytes = encoded_as_bytes + (b\"=\" * (4 - mod))\n",
      "    assert (len(encoded_as_bytes) % 4) == 0\n",
      "    result = base64.urlsafe_b64decode(encoded_as_bytes)\n",
      "    if encoding:\n",
      "        return codecs.decode(result, 'utf-8')\n",
      "    return result\n",
      "Investigating:  encoding@FunctionDef_0x16e393f83b4b2d8b\n",
      "Predicted class:\n",
      "bool\t0.9997\n",
      "Union\t0.0002\n",
      "int\t0.0001\n",
      "True class: Optional\n",
      "Input saliency\n",
      "       ids     score                                     name         type\n",
      "0   140757  0.275501                    If_0x16e393f83b9d6884           If\n",
      "1   493821  0.011624                Return_0x16e393f83bb0e1b2       Return\n",
      "2    11083  0.010450  encoding@FunctionDef_0x16e393f83b4b2d8b      mention\n",
      "3   285707  0.009245                   arg_0x16e393f83b9a2c8c          arg\n",
      "4   419757  0.007014           FunctionDef_0x16e393f83b4b2d8b  FunctionDef\n",
      "5   259296  0.002031                                ▁encoding      subword\n",
      "6  2125516  0.001988                Module_0x16e393f83bd4c75d       Module\n",
      "7  1333223  0.001582                Return_0x16e393f83bf72820       Return\n",
      "8  2013323  0.001081             arguments_0x16e393f83b14892f    arguments\n",
      "9   679699  0.000747                  Call_0x16e393f83bee6e8a         Call\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1864 [00:07<1:43:55,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " class ExtensionEmbed(NamedTuple):\n",
      "    artifact_path: str\n",
      "    server_url: str\n",
      "    cdn_url: Optional[str] = None\n",
      "Investigating:  cdn_url@ClassDef_0x16e393f1de4cae84\n",
      "Predicted class:\n",
      "Optional\t1.0000\n",
      "str\t0.0000\n",
      "int\t0.0000\n",
      "True class: Optional\n",
      "Input saliency\n",
      "       ids         score                                       name         type\n",
      "0    69376  6.838461e-07               AnnAssign_0x16e393f1de9bf4f9    AnnAssign\n",
      "1  2101673  6.102767e-07  bokeh.embed.bundle.ExtensionEmbed.cdn_url  class_field\n",
      "2  1396154  1.824241e-07                          Constant_NoneType     Constant\n",
      "3    27710  1.102966e-07        cdn_url@ClassDef_0x16e393f1de4cae84      mention\n",
      "4  1582286  8.070634e-08                ClassDef_0x16e393f1de4cae84     ClassDef\n",
      "5  2545114  5.333061e-08               AnnAssign_0x16e393f1de552f33    AnnAssign\n",
      "6  1652746  2.194407e-08                  Module_0x16e393f1ddf954f7       Module\n",
      "7   940594  3.660112e-09     server_url@ClassDef_0x16e393f1de4cae84      mention\n",
      "8  1153831  2.229120e-09               AnnAssign_0x16e393f1de0450c5    AnnAssign\n",
      "9  1745199  2.002060e-09                                          _      subword\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1864 [00:07<1:16:44,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def hexbin(x: Any, y: Any, size: float, orientation: str = \"pointytop\", aspect_scale: float = 1) -> Any:\n",
      "    ''' Perform an equal-weight binning of data points into hexagonal tiles.\n",
      "\n",
      "    For more sophisticated use cases, e.g. weighted binning or scaling\n",
      "    individual tiles proportional to some other quantity, consider using\n",
      "    HoloViews.\n",
      "\n",
      "    Args:\n",
      "        x (array[float]) :\n",
      "            A NumPy array of x-coordinates for binning\n",
      "\n",
      "        y (array[float]) :\n",
      "            A NumPy array of y-coordinates for binning\n",
      "\n",
      "        size (float) :\n",
      "            The size of the hexagonal tiling.\n",
      "\n",
      "            The size is defined as the distance from the center of a hexagon\n",
      "            to the top corner for \"pointytop\" orientation, or from the center\n",
      "            to a side corner for \"flattop\" orientation.\n",
      "\n",
      "        orientation (str, optional) :\n",
      "            Whether the hex tile orientation should be \"pointytop\" or\n",
      "            \"flattop\". (default: \"pointytop\")\n",
      "\n",
      "        aspect_scale (float, optional) :\n",
      "            Match a plot's aspect ratio scaling.\n",
      "\n",
      "            When working with a plot with ``aspect_scale != 1``, this\n",
      "            parameter can be set to match the plot, in order to draw\n",
      "            regular hexagons (instead of \"stretched\" ones).\n",
      "\n",
      "            This is roughly equivalent to binning in \"screen space\", and\n",
      "            it may be better to use axis-aligned rectangular bins when\n",
      "            plot aspect scales are not one.\n",
      "\n",
      "    Returns:\n",
      "        DataFrame\n",
      "\n",
      "        The resulting DataFrame will have columns *q* and *r* that specify\n",
      "        hexagon tile locations in axial coordinates, and a column *counts* that\n",
      "        provides the count for each tile.\n",
      "\n",
      "    .. warning::\n",
      "        Hex binning only functions on linear scales, i.e. not on log plots.\n",
      "\n",
      "    '''\n",
      "    pd: Any = import_required('pandas','hexbin requires pandas to be installed')\n",
      "\n",
      "    q, r = cartesian_to_axial(x, y, size, orientation, aspect_scale=aspect_scale)\n",
      "\n",
      "    df = pd.DataFrame(dict(r=r, q=q))\n",
      "\n",
      "    return df.groupby(['q', 'r']).size().reset_index(name='counts')\n",
      "Investigating:  size@FunctionDef_0x16e393f48e467b31\n",
      "Predicted class:\n",
      "JSONInput\t0.4963\n",
      "Number\t0.1588\n",
      "RequestType\t0.1246\n",
      "True class: float\n",
      "Input saliency\n",
      "       ids     score                                               name       type\n",
      "0  1282911  0.335902                            Call_0x16e393f48eeb3171       Call\n",
      "1  1238536  0.254414                         keyword_0x16e393f48e1d89c2    keyword\n",
      "2   981548  0.090522                                              axial    subword\n",
      "3  1745199  0.088395                                                  _    subword\n",
      "4   834314  0.070706  cartesian_to_axial@FunctionDef_0x16e393f48e467b31    mention\n",
      "5  1250744  0.069642                                       aspect_scale  #keyword#\n",
      "6  1110742  0.060424                                         ▁cartesian    subword\n",
      "7   326198  0.042137                       arguments_0x16e393f48e44b7c6  arguments\n",
      "8   236348  0.024561                  bokeh.util.hex.cartesian_to_axial   function\n",
      "9  1450257  0.023035                             arg_0x16e393f48e2bbc7f        arg\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1864 [00:08<58:36,  1.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def linear_palette(palette: Palette, n: int) -> Palette:\n",
      "    ''' Generate a new palette as a subset of a given palette.\n",
      "\n",
      "    Given an input ``palette``, take ``n`` colors from it by dividing its\n",
      "    length into ``n`` (approximately) evenly spaced indices.\n",
      "\n",
      "    Args:\n",
      "\n",
      "        palette (seq[str]) : a sequence of hex RGB color strings\n",
      "        n (int) : the size of the output palette to generate\n",
      "\n",
      "    Returns:\n",
      "        seq[str] : a sequence of hex RGB color strings\n",
      "\n",
      "    Raises:\n",
      "        ``ValueError`` if ``n > len(palette)``\n",
      "\n",
      "    '''\n",
      "    if n > len(palette):\n",
      "        raise ValueError(\"Requested %(r)s colors, function can only return colors up to the base palette's length (%(l)s)\" % dict(r=n, l=len(palette)))\n",
      "    return tuple( palette[int(math.floor(i))] for i in np.linspace(0, len(palette)-1, num=n) )\n",
      "Investigating:  palette@FunctionDef_0x16e393f775f913a4\n",
      "Predicted class:\n",
      "Sequence\t0.8297\n",
      "Dict\t0.1111\n",
      "Palette\t0.0572\n",
      "True class: Palette\n",
      "Input saliency\n",
      "       ids     score                                name          type\n",
      "0   102952  0.264027        Subscript_0x16e393f77571adb6     Subscript\n",
      "1  2229729  0.140319                                ▁len       subword\n",
      "2  2301568  0.067374                        builtins.len      function\n",
      "3   968980  0.064227  len@FunctionDef_0x16e393f775f913a4       mention\n",
      "4   738375  0.051444             Call_0x16e393f7755b01d6          Call\n",
      "5  2324679  0.051313             Call_0x16e393f775d0f08c          Call\n",
      "6   138564  0.048163             Call_0x16e393f7754f149d          Call\n",
      "7  2169145  0.034154        arguments_0x16e393f7756008dd     arguments\n",
      "8  1747366  0.033502     GeneratorExp_0x16e393f775be8160  GeneratorExp\n",
      "9  1685060  0.018966          keyword_0x16e393f775ef4b77       keyword\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1864 [00:08<45:59,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def nice_join(seq: Sequence[str], sep: str = \", \", conjuction: str = \"or\") -> str:\n",
      "    ''' Join together sequences of strings into English-friendly phrases using\n",
      "    the conjunction ``or`` when appropriate.\n",
      "\n",
      "    Args:\n",
      "        seq (seq[str]) : a sequence of strings to nicely join\n",
      "        sep (str, optional) : a sequence delimiter to use (default: \", \")\n",
      "        conjunction (str or None, optional) : a conjuction to use for the last\n",
      "            two items, or None to reproduce basic join behaviour (default: \"or\")\n",
      "\n",
      "    Returns:\n",
      "        a joined string\n",
      "\n",
      "    Examples:\n",
      "        >>> nice_join([\"a\", \"b\", \"c\"])\n",
      "        'a, b or c'\n",
      "\n",
      "    '''\n",
      "    seq = [str(x) for x in seq]\n",
      "\n",
      "    if len(seq) <= 1 or conjuction is None:\n",
      "        return sep.join(seq)\n",
      "    else:\n",
      "        return \"%s %s %s\" % (sep.join(seq[:-1]), conjuction, seq[-1])\n",
      "Investigating:  seq@FunctionDef_0x16e393f61773c7da\n",
      "Predicted class:\n",
      "Sequence\t0.9906\n",
      "bytes\t0.0093\n",
      "Union\t0.0001\n",
      "True class: Sequence\n",
      "Input saliency\n",
      "       ids     score                                name           type\n",
      "0   876389  0.005443        Subscript_0x16e393f61720d4c3      Subscript\n",
      "1  1770862  0.004975        Subscript_0x16e393f61745b255      Subscript\n",
      "2  1480318  0.002842    comprehension_0x16e393f6175abe25  comprehension\n",
      "3  2638829  0.001608           Assign_0x16e393f61777eb0b         Assign\n",
      "4   439993  0.000689            Slice_0x16e393f6170e071d          Slice\n",
      "5    44903  0.000557  seq@FunctionDef_0x16e393f61773c7da        mention\n",
      "6   946779  0.000552         ListComp_0x16e393f6179bd15e       ListComp\n",
      "7  2233734  0.000218             Call_0x16e393f6171e849d           Call\n",
      "8  2332105  0.000182              arg_0x16e393f617180f5c            arg\n",
      "9  1434719  0.000178        Attribute_0x16e393f617494428      Attribute\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1864 [00:09<38:40,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def red(text: str) -> str:    return \"%s%s%s\" % (Fore.RED, text, Style.RESET_ALL)\n",
      "Investigating:  text@FunctionDef_0x16e393f89887a81b\n",
      "Predicted class:\n",
      "int\t0.7621\n",
      "str\t0.2378\n",
      "TracebackType\t0.0001\n",
      "True class: str\n",
      "Input saliency\n",
      "       ids     score                                 name         type\n",
      "0  1896862  0.146427             Tuple_0x16e393f898c5b477        Tuple\n",
      "1  2575840  0.101647         arguments_0x16e393f8988b4e61    arguments\n",
      "2  2414025  0.087682         Attribute_0x16e393f8984a407c    Attribute\n",
      "3  2013294  0.081670         Attribute_0x16e393f898f935ef    Attribute\n",
      "4  1360552  0.033268               arg_0x16e393f898cfeba2          arg\n",
      "5   479867  0.027198                                  RED       #attr#\n",
      "6  2374696  0.027137                            RESET_ALL       #attr#\n",
      "7   386162  0.012943             BinOp_0x16e393f898a11fde        BinOp\n",
      "8    59093  0.004072  text@FunctionDef_0x16e393f89887a81b      mention\n",
      "9   282232  0.003445       FunctionDef_0x16e393f89887a81b  FunctionDef\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1864 [00:09<31:27,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def invoke(self, args: argparse.Namespace) -> None:\n",
      "        '''\n",
      "\n",
      "        '''\n",
      "        argvs = { f : args.args for f in args.files}\n",
      "        applications = build_single_handler_applications(args.files, argvs)\n",
      "\n",
      "        if args.output is None:\n",
      "            outputs: List[str] = []\n",
      "        else:\n",
      "            outputs = list(args.output)  # copy so we can pop from it\n",
      "\n",
      "        if len(outputs) > len(applications):\n",
      "            die(\"--output/-o was given too many times (%d times for %d applications)\" %\n",
      "                (len(outputs), len(applications)))\n",
      "\n",
      "        for (route, app) in applications.items():\n",
      "            doc = app.create_document()\n",
      "\n",
      "            if len(outputs) > 0:\n",
      "                filename = outputs.pop(0)\n",
      "            else:\n",
      "                filename = self.filename_from_route(route, self.extension)\n",
      "\n",
      "            self.write_file(args, filename, doc)\n",
      "Investigating:  args@FunctionDef_0x16e393f34a01a586\n",
      "Predicted class:\n",
      "Type\t0.6661\n",
      "_CodeWriter\t0.3107\n",
      "Rule\t0.0170\n",
      "True class: Namespace\n",
      "Input saliency\n",
      "       ids     score                          name       type\n",
      "0   334063  2.244393  Attribute_0x16e393f34a395394  Attribute\n",
      "1  1228997  0.539854       Call_0x16e393f34a77cdfb       Call\n",
      "2  1292142  0.367827                    write_file     #attr#\n",
      "3  2542361  0.279852  Attribute_0x16e393f34a49e61e  Attribute\n",
      "4  1487288  0.221349  Attribute_0x16e393f34a555db2  Attribute\n",
      "5    85650  0.221319  Attribute_0x16e393f34a03f50b  Attribute\n",
      "6  2569386  0.221024  Attribute_0x16e393f34ae73a13  Attribute\n",
      "7  1210090  0.220908  Attribute_0x16e393f34a067a5d  Attribute\n",
      "8  1545645  0.194278                          args     #attr#\n",
      "9   394199  0.161106                        output     #attr#\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/1864 [00:10<25:59,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def report_server_init_errors(address: Optional[str] = None, port: Optional[int] = None, **kwargs: str) -> Iterator[None]:\n",
      "    ''' A context manager to help print more informative error messages when a\n",
      "    ``Server`` cannot be started due to a network problem.\n",
      "\n",
      "    Args:\n",
      "        address (str) : network address that the server will be listening on\n",
      "\n",
      "        port (int) : network address that the server will be listening on\n",
      "\n",
      "    Example:\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            with report_server_init_errors(**server_kwargs):\n",
      "                server = Server(applications, **server_kwargs)\n",
      "\n",
      "        If there are any errors (e.g. port or address in already in use) then a\n",
      "        critical error will be logged and the process will terminate with a\n",
      "        call to ``sys.exit(1)``\n",
      "\n",
      "    '''\n",
      "    try:\n",
      "        yield\n",
      "    except EnvironmentError as e:\n",
      "        if e.errno == errno.EADDRINUSE:\n",
      "            log.critical(\"Cannot start Bokeh server, port %s is already in use\", port)\n",
      "        elif e.errno == errno.EADDRNOTAVAIL:\n",
      "            log.critical(\"Cannot start Bokeh server, address '%s' not available\", address)\n",
      "        else:\n",
      "            codename = errno.errorcode[e.errno]\n",
      "            log.critical(\"Cannot start Bokeh server [%s]: %r\", codename, e)\n",
      "        sys.exit(1)\n",
      "Investigating:  address@FunctionDef_0x16e393f3517f3d22\n",
      "Predicted class:\n",
      "str\t0.7351\n",
      "int\t0.2627\n",
      "Optional\t0.0022\n",
      "True class: Optional\n",
      "Input saliency\n",
      "       ids     score                                name             type\n",
      "0  1288628  4.735777        Attribute_0x16e393f351cb420e        Attribute\n",
      "1  1379531  0.937891                            critical           #attr#\n",
      "2   570429  0.258349             Call_0x16e393f35139fab8             Call\n",
      "3  1129607  0.184880  log@FunctionDef_0x16e393f3517f3d22          mention\n",
      "4  2412953  0.182609        arguments_0x16e393f351a2a165        arguments\n",
      "5  2530369  0.067920               If_0x16e393f351c13a91               If\n",
      "6   464254  0.036477                        Constant_str         Constant\n",
      "7  1648372  0.016982              arg_0x16e393f3514fcbbe              arg\n",
      "8  2190296  0.016320                                ▁log          subword\n",
      "9   525857  0.009359              bokeh.command.util.log  global_variable\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1864 [00:10<22:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def set_single_plot_width_height(doc: Document, width: Optional[int], height: Optional[int]) -> None:\n",
      "    if width is not None or height is not None:\n",
      "        layout = doc.roots\n",
      "        if len(layout) != 1 or not isinstance(layout[0], Plot):\n",
      "            warnings.warn(\"Width/height arguments will be ignored for this muliple layout. (Size valus only apply when exporting single plots.)\")\n",
      "        else:\n",
      "            plot = layout[0]\n",
      "            # TODO - below fails mypy check\n",
      "            # unsure how to handle with typing. width is int base type and class property getter is typing.Int\n",
      "            # plot.plot_width  = width if width is not None else plot.plot_width  # doesnt solve problem\n",
      "            plot.plot_height = height or plot.plot_height\n",
      "            plot.plot_width  = width or plot.plot_width\n",
      "Investigating:  height@FunctionDef_0x16e393f3521f6615\n",
      "Predicted class:\n",
      "Any\t0.5652\n",
      "int\t0.2723\n",
      "Dict\t0.1374\n",
      "True class: Optional\n",
      "Input saliency\n",
      "       ids     score                          name       type\n",
      "0  1330382  0.152810    Compare_0x16e393f352bc4abc    Compare\n",
      "1  1353336  0.085995     BoolOp_0x16e393f3524317fb     BoolOp\n",
      "2   183679  0.062458                            Or         Op\n",
      "3   579409  0.025293        arg_0x16e393f352e7ac99        arg\n",
      "4  1660349  0.024890  arguments_0x16e393f352de4ac8  arguments\n",
      "5  1219864  0.022957  Attribute_0x16e393f352e7956d  Attribute\n",
      "6   689527  0.017839                         IsNot         Op\n",
      "7  2142562  0.007400     Assign_0x16e393f35292bad2     Assign\n",
      "8  1269900  0.006195                   plot_height     #attr#\n",
      "9  1396154  0.005318             Constant_NoneType   Constant\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1864 [00:11<34:29,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " def _version(modname: str, attr: str) -> Optional[Any]:\n",
      "    mod = import_optional(modname)\n",
      "    if mod:\n",
      "        return getattr(mod, attr)\n",
      "    else:  # explicit None return for mypy typing\n",
      "        return None\n",
      "Investigating:  modname@FunctionDef_0x16e393f5116bb8d6\n",
      "Predicted class:\n",
      "int\t0.8102\n",
      "str\t0.1898\n",
      "Optional\t0.0000\n",
      "True class: str\n",
      "Input saliency\n",
      "       ids     score                                            name       type\n",
      "0  1412303  0.024165                         Call_0x16e393f511ce83ac       Call\n",
      "1   828631  0.023561                          arg_0x16e393f511d07e01        arg\n",
      "2    43748  0.020011  import_optional@FunctionDef_0x16e393f5116bb8d6    mention\n",
      "3  2149820  0.016519         bokeh.util.dependencies.import_optional   function\n",
      "4  1739571  0.015651                    arguments_0x16e393f511e303e9  arguments\n",
      "5  1025498  0.011001                                        optional    subword\n",
      "6   873758  0.011000                                         ▁import    subword\n",
      "7  1745199  0.008597                                               _    subword\n",
      "8  1863594  0.003844                       Assign_0x16e393f511252535     Assign\n",
      "9    95391  0.003010          modname@FunctionDef_0x16e393f5116bb8d6    mention\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compute_saliency(\n",
    "    dataset,\n",
    "    model_name=RGCN,\n",
    "    model_params=config[\"MODEL\"],\n",
    "    trainer_params=config[\"TRAINING\"],\n",
    "    model_base_path=checkpoint_path,\n",
    "    trainer=SamplingMultitaskTrainerWithSaliency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SourceCodeTools",
   "language": "python",
   "name": "sourcecodetools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}