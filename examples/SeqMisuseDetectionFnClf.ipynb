{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To train a variable misuse detection model one needs to implement an NLP labeling model.\n",
    "\n",
    "For example, for a funciton containing misuse\n",
    "```\n",
    "def _eq(l1, l2):\\n    return (set(l1) == set(l1))\n",
    "```\n",
    "the misuse character span is (44, 46). To do this with NLP methods, code is tokenized, and labels for tokens are generated\n",
    "```\n",
    "[def, _, eq, (, l, 1, \",\", l, 2, ):, \\n, \\t, return, (, set, (, l1, ), ==, set, (, l1, ), ), ]\n",
    "[O  , O, O , O, O, O,  O , O, O, 0 , O , O ,    O  , O, O  , O, O , O, O , O  , O, M , O, O, O\n",
    "```\n",
    "The goal is to train an NLP model that predicts those labels correctly. In this project, BILUO labeling scheme is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The goal of this project\n",
    "1. Verify dataset, make sure that encoded batches are correct (misuse spans are correct). You can sample dataset and make sure that the number of errors is less than a certain threshold.\n",
    "2. Train variable misuse detection model (with finetuning and without)\n",
    "3. Verify [scoring function](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/entity/type_prediction.py#L71)\n",
    "4. Conduct a series of experiments to identify performance\n",
    "5. Analyze errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Why using this example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Basic functionality, necessary for train an NLP labeler is\n",
    "1. Loading data (implemented in this example)\n",
    "2. Tokenization, preparing labels (implemented in [`PythonBatcher.prepare_sent`](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/batchers/PythonBatcher.py#L123))\n",
    "3. Data encoding for using with ML models (implemented in [`PythonBatcher.create_batches_with_mask`](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/batchers/PythonBatcher.py#L206))\n",
    "4. Batching (implemented in [`PythonBatcher.format_batch`](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/batchers/PythonBatcher.py#L256))\n",
    "5. Model training (partially implemented in [`CodeBertModelTrainer2.train_model`](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/codebert/codebert_train.py#L148) and extended here)\n",
    "6. Tensorboard tracking (implemented in `CodeBertModelTrainer2`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. See [installation steps](https://github.com/VitalyRomanov/method-embedding#installing-python-libraries).\n",
    "\n",
    "2. Install transformers\n",
    "```bash\n",
    "pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from argparse import Namespace\n",
    "from SourceCodeTools.nlp.codebert.codebert_train import CodeBertModelTrainer2, CodebertHybridModel, batch_to_torch\n",
    "from SourceCodeTools.nlp.entity.type_prediction import scorer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from time import time\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "from typing import Dict, Optional, List, Union\n",
    "from SourceCodeTools.nlp.tokenizers import _inject_tokenizer\n",
    "# from sqlitedict import SqliteDict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import diskcache as dc\n",
    "\n",
    "\n",
    "from SourceCodeTools.nlp.entity import fix_incorrect_tags\n",
    "from SourceCodeTools.code.annotator_utils import adjust_offsets, biluo_tags_from_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenizer\n",
    "\n",
    "Current code works with many tokenizers. The most comparible format for storing labels is to store them as character spans. Character spans for labels are mapped to tokens with Spacy's `biluo_tags_from_offsets`. For this reason, we need to have instruments to make tokenizers compatible with Spacy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AdapterDoc:\n",
    "    \"\"\"\n",
    "    A simple wrapper for tokens that also stores additional data such as character span adjustment and \n",
    "    tokens compatible with `biluo_tags_from_offsets`\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.adjustment_amount = 0\n",
    "        self.tokens_for_biluo_alignment = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tokens)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\".join(self.tokens)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "\n",
    "class CodebertAdapter:\n",
    "    \"\"\"\n",
    "    This tokenizer returns tokens in a format that can be used with `biluo_tags_from_offsets`\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        from transformers import RobertaTokenizer\n",
    "        import spacy\n",
    "\n",
    "        # create primary tokenizer\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "        # create secondary tokenizer, need this to fix token alignment errors\n",
    "        self.regex_tok = create_tokenizer(\"regex\")\n",
    "        # need to have a blank spacy model for compatibility\n",
    "        self.nlp = spacy.blank(\"en\")\n",
    "\n",
    "    def primary_tokenization(self, text):\n",
    "        return self.tokenizer.tokenize(text)\n",
    "\n",
    "    def secondary_tokenization(self, tokens):\n",
    "        # secondary tokenizer performs subtokenization \n",
    "        # example:\n",
    "        # \"(arg1\" -> \"(\", \"arg1\"\n",
    "        new_tokens = []\n",
    "        for token in tokens:\n",
    "            new_tokens.extend(self.regex_tok(token))\n",
    "        return new_tokens\n",
    "\n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "        Tokenization function. Example:\n",
    "            original string: 'a + b'\n",
    "            codebert tokenized: '<s>', 'a', 'Ġ+', 'Ġb', '</s>'\n",
    "        \"\"\"\n",
    "        from spacy.tokens import Doc\n",
    "        tokens = self.primary_tokenization(text)\n",
    "        tokens = self.secondary_tokenization(tokens)\n",
    "        doc = Doc(self.nlp.vocab, tokens, spaces=[False] * len(tokens))\n",
    "\n",
    "        backup_tokens = doc\n",
    "        fixed_spaces = [False]\n",
    "        fixed_words = [\"<s>\"]  # add additional tokens for codebert to avoid adding them later.\n",
    "\n",
    "        for ind, t in enumerate(doc):\n",
    "            if len(t.text) > 1:\n",
    "                fixed_words.append(t.text.strip(\"Ġ\"))\n",
    "            else:\n",
    "                fixed_words.append(t.text)\n",
    "            if ind != 0:\n",
    "                fixed_spaces.append(t.text.startswith(\"Ġ\") and len(t.text) > 1)\n",
    "        fixed_spaces.append(False)\n",
    "        fixed_spaces.append(False)\n",
    "        fixed_words.append(\"</s>\")\n",
    "\n",
    "        assert len(fixed_spaces) == len(fixed_words)\n",
    "\n",
    "        doc = Doc(self.nlp.vocab, fixed_words, fixed_spaces)\n",
    "\n",
    "        assert len(doc) - 2 == len(backup_tokens)\n",
    "        assert len(doc.text) - 7 == len(backup_tokens.text)\n",
    "\n",
    "        final_doc = AdapterDoc([\"<s>\"] + [t.text for t in backup_tokens] + [\"</s>\"])\n",
    "        final_doc.adjustment_amount = -3\n",
    "        final_doc.tokens_for_biluo_alignment = doc\n",
    "\n",
    "        return final_doc\n",
    "    \n",
    "    \n",
    "def create_tokenizer(type, bpe_path=None, regex=None):\n",
    "    if type == \"spacy\":\n",
    "        import spacy\n",
    "        print(\"Creating spacy tokenizer\")\n",
    "        return _inject_tokenizer(spacy.blank(\"en\"))\n",
    "    elif type == \"codebert\":\n",
    "        from transformers import RobertaTokenizer\n",
    "        import spacy\n",
    "        from spacy.tokens import Doc\n",
    "        print(\"Creating CodeBERT tokenizer\")\n",
    "        adapter = CodebertAdapter()\n",
    "\n",
    "        def tokenize(text):\n",
    "            return adapter(text)\n",
    "\n",
    "        return tokenize\n",
    "    else:\n",
    "        raise Exception(\"Supported tokenizer types: spacy, regex, bpe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, List, Union\n",
    "from SourceCodeTools.nlp import create_tokenizer, tag_map_from_sentences, TagMap, token_hasher, try_int, ValueEncoder\n",
    "\n",
    "\n",
    "class SampleEntry(object):\n",
    "    def __init__(self, id, text, labels=None, category=None, **kwargs):\n",
    "        self._storage = dict()\n",
    "        self._storage[\"id\"] = id\n",
    "        self._storage[\"text\"] = text\n",
    "        self._storage[\"labels\"] = labels\n",
    "        self._storage[\"category\"] = category\n",
    "        self._storage.update(kwargs)\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        storage = object.__getattribute__(self, \"_storage\")\n",
    "        if item in storage:\n",
    "            return storage[item]\n",
    "        return super().__getattribute__(item)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self._storage)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self._storage[item]\n",
    "\n",
    "    def keys(self):\n",
    "        return list(self._storage.keys())\n",
    "\n",
    "\n",
    "class MapperSpec:\n",
    "    def __init__(self, field, target_field, encoder, dtype=np.int32, preproc_fn=None):\n",
    "        self.field = field\n",
    "        self.target_field = target_field\n",
    "        self.encoder = encoder\n",
    "        self.preproc_fn = preproc_fn\n",
    "        self.dtype = dtype\n",
    "\n",
    "        \n",
    "class SimplePythonBatcher:\n",
    "    def __init__(\n",
    "            self, data, batch_size: int, seq_len: int,\n",
    "            wordmap: Dict[str, int], *, tagmap: Optional[TagMap] = None,\n",
    "            class_weights=False, element_hash_size=1000, sort_by_length=True, tokenizer=\"spacy\", no_localization=False,\n",
    "            cache_dir: Optional[Union[str, Path]] = None, **kwargs\n",
    "    ):\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._batch_count = None\n",
    "        self._max_seq_len = seq_len\n",
    "        self._tokenizer = tokenizer\n",
    "        self._class_weights = None\n",
    "        self._no_localization = no_localization\n",
    "        self._nlp = create_tokenizer(tokenizer)\n",
    "        self._cache_dir = Path(cache_dir) if cache_dir is not None else cache_dir\n",
    "        self._valid_sentences = 0\n",
    "        self._filtered_sentences = 0\n",
    "        self._wordmap = wordmap\n",
    "        self.tagmap = tagmap\n",
    "        self._sort_by_length = sort_by_length\n",
    "        self._data = data\n",
    "        self._length = None\n",
    "\n",
    "        self._create_cache()\n",
    "        self._prepare_data(data)\n",
    "        self._create_mappers(**kwargs)\n",
    "\n",
    "    def _get_version_code(self):\n",
    "        defining_parameters = json.dumps({\n",
    "            \"tokenizer\": self._tokenizer, \"max_seq_len\": self._max_seq_len\n",
    "        })\n",
    "        return self._compute_text_id(defining_parameters)\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_text_id(text):\n",
    "        return int(hashlib.md5(text.encode('utf-8')).hexdigest(), 16) % 1152921504606846976\n",
    "\n",
    "    def _check_cache_dir(self):\n",
    "        if not hasattr(self, \"_cache_dir\") or self._cache_dir is None:\n",
    "            raise Exception(\"Cache directory location has not been specified yet\")\n",
    "\n",
    "    def _get_cache_location_name(self, cache_name):\n",
    "        self._check_cache_dir()\n",
    "        return str(self._cache_dir.joinpath(cache_name))\n",
    "\n",
    "    @property\n",
    "    def _data_cache_path(self):\n",
    "        return self._get_cache_location_name(\"DataCache\")\n",
    "\n",
    "    # @property\n",
    "    # def _sent_cache_path(self):\n",
    "    #     return self._get_cache_location_name(\"SentCache\")\n",
    "\n",
    "    @property\n",
    "    def _batch_cache_path(self):\n",
    "        return self._get_cache_location_name(\"BatchCache\")\n",
    "\n",
    "    @property\n",
    "    def _tagmap_path(self):\n",
    "        return self._cache_dir.joinpath(\"tagmap.json\")\n",
    "\n",
    "    def _create_cache(self):\n",
    "        if self._cache_dir is None:\n",
    "            self._tmp_dir = tempfile.TemporaryDirectory()\n",
    "            self._cache_dir = Path(self._tmp_dir.name)\n",
    "\n",
    "        self._cache_dir = self._cache_dir.joinpath(f\"PythonBatcher{self._get_version_code()}\")\n",
    "        self._cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created cache directory at location {self._cache_dir}\")\n",
    "\n",
    "        # self._data_cache = SqliteDict(self._data_cache_path) # dc.Cache(self._data_cache_path)\n",
    "        # # self._sent_cache = dc.Cache(self._sent_cache_path)\n",
    "        # self._batch_cache = SqliteDict(self._batch_cache_path) #dc.Cache(self._batch_cache_path)\n",
    "        \n",
    "    def _parse_entry(self, text, annotations):\n",
    "        id_ = self._compute_text_id(text)\n",
    "        extra = copy(annotations)\n",
    "        labels = extra.pop(\"entities\")\n",
    "        extra.update(self._prepare_tokenized_sent((text, annotations)))\n",
    "        return SampleEntry(id=id_, text=text, labels=labels, **extra)\n",
    "\n",
    "    def _prepare_data(self, data):\n",
    "        pass\n",
    "#         self._sent_lenghts = {}\n",
    "\n",
    "#         for text, annotations in tqdm(data, desc=\"Preprocess functions\"):\n",
    "#             id_ = self._compute_text_id(text)\n",
    "#             if id_ not in self._data_cache:\n",
    "#                 extra = copy(annotations)\n",
    "#                 labels = extra.pop(\"entities\")\n",
    "#                 extra.update(self._prepare_tokenized_sent((text, annotations)))\n",
    "#                 entry = SampleEntry(id=id_, text=text, labels=labels, **extra)\n",
    "#                 self._data_cache[id_] = entry\n",
    "#             else:\n",
    "#                 entry = self._data_cache[id_]\n",
    "#             self._sent_lenghts[id_] = len(entry.tokens)\n",
    "        \n",
    "#     def _iterate_record_ids(self):\n",
    "#         return self._data_cache.iterkeys()\n",
    "    \n",
    "#     def _get_record_with_id(self, id):\n",
    "#         if id not in self._data_cache:\n",
    "#             raise KeyError(\"Record with such id is not found\")\n",
    "#         return self._data_cache[id]\n",
    "\n",
    "#     def _iterate_sorted_by_length(self, limit_max_length=False):\n",
    "#         for id_, length in sorted(self._sent_lenghts.items(), key=lambda x: x[1]):\n",
    "#             if limit_max_length and length >= self._max_seq_len:\n",
    "#                 continue\n",
    "#             yield self._get_record_with_id(id_)\n",
    "\n",
    "    def _iterate_records(self, limit_max_length=False, shuffle=False):\n",
    "        for data, annotations in self._data:\n",
    "            entry = self._parse_entry(data, annotations)\n",
    "            if limit_max_length and len(entry.tokens) >= self._max_seq_len:\n",
    "                continue\n",
    "            yield entry\n",
    "        # for id_ in self._sent_lenghts.keys():\n",
    "        #     if limit_max_length and self._sent_lenghts[id_] >= self._max_seq_len:\n",
    "        #         continue\n",
    "        #     yield self._get_record_with_id(id_)\n",
    "\n",
    "    def _create_mappers(self, **kwargs):\n",
    "        self._mappers = []\n",
    "        self._create_wordmap_encoder()\n",
    "        # self._create_tagmap_encoder()\n",
    "\n",
    "    def _create_tagmap_encoder(self):\n",
    "        if self.tagmap is None:\n",
    "            if self._tagmap_path.is_file():\n",
    "                tagmap = TagMap.load(self._tagmap_path)\n",
    "            else:\n",
    "                def iterate_tags():\n",
    "                    for record in self._iterate_records():\n",
    "                        for label in record.tags:\n",
    "                            yield label\n",
    "\n",
    "                tagmap = tag_map_from_sentences(iterate_tags())\n",
    "                tagmap.set_default(tagmap._value_to_code[\"O\"])\n",
    "                tagmap.save(self._tagmap_path)\n",
    "\n",
    "            self.tagmap = tagmap\n",
    "\n",
    "        self._mappers.append(\n",
    "            MapperSpec(field=\"tags\", target_field=\"tags\", encoder=self.tagmap)\n",
    "        )\n",
    "        # self.tagmap = tagmap\n",
    "        # self.tagpad = self.tagmap[\"O\"]\n",
    "\n",
    "    def _create_wordmap_encoder(self):\n",
    "        wordmap_enc = ValueEncoder(value_to_code=self._wordmap)\n",
    "        wordmap_enc.set_default(len(self._wordmap))\n",
    "        self._mappers.append(\n",
    "            MapperSpec(field=\"tokens\", target_field=\"tok_ids\", encoder=wordmap_enc)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2  # binary classification\n",
    "\n",
    "    def _prepare_tokenized_sent(self, sent):\n",
    "        text, annotations = sent\n",
    "\n",
    "        doc = self._nlp(text)\n",
    "        label = 1.0 if len(annotations['entities']) > 0 else 0.\n",
    "\n",
    "        tokens = doc\n",
    "        try:\n",
    "            tokens = [t.text for t in tokens]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        output = {\n",
    "            \"tokens\": tokens,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    # @lru_cache(maxsize=200000)\n",
    "    def _encode_for_batch(self, record):\n",
    "\n",
    "        # if record.id in self._batch_cache:\n",
    "            # return self._batch_cache[record.id]\n",
    "\n",
    "        def encode(seq, encoder, pad, preproc_fn=None):\n",
    "            if preproc_fn is None:\n",
    "                def preproc_fn(x):\n",
    "                    return x\n",
    "            blank = np.ones((self._max_seq_len,), dtype=np.int32) * pad\n",
    "            encoded = np.array([encoder[preproc_fn(w)] for w in seq], dtype=np.int32)\n",
    "            blank[0:min(encoded.size, self._max_seq_len)] = encoded[0:min(encoded.size, self._max_seq_len)]\n",
    "            return blank\n",
    "\n",
    "        output = {}\n",
    "\n",
    "        for mapper in self._mappers:\n",
    "            output[mapper.target_field] = encode(\n",
    "                seq=record[mapper.field], encoder=mapper.encoder, pad=mapper.encoder.default,\n",
    "                preproc_fn=mapper.preproc_fn\n",
    "            ).astype(mapper.dtype)\n",
    "\n",
    "        tokens = record.tokens\n",
    "        num_tokens = len(tokens)\n",
    "\n",
    "        # assert len(s) == len(t)\n",
    "\n",
    "        # output[\"no_loc_mask\"] = np.array([tag != self.tagmap.default for tag in output[\"tags\"]]).astype(np.bool)\n",
    "        output[\"lens\"] = num_tokens if num_tokens < self._max_seq_len else self._max_seq_len\n",
    "        output[\"label\"] = record[\"label\"]\n",
    "\n",
    "        # self._batch_cache[record.id] = output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def format_batch(self, batch):\n",
    "        fbatch = defaultdict(list)\n",
    "\n",
    "        for sent in batch:\n",
    "            for key, val in sent.items():\n",
    "                fbatch[key].append(val)\n",
    "\n",
    "        max_len = max(fbatch[\"lens\"])\n",
    "\n",
    "        return {\n",
    "            key: np.stack(val)[:,:max_len] if key != \"lens\" and key != \"replacements\" and key != \"tokens\" and  key != \"label\"\n",
    "            else (np.array(val, dtype=np.int32) if key == \"lens\" or key == \"label\" else np.array(val)) for key, val in fbatch.items()}\n",
    "\n",
    "    def generate_batches(self):\n",
    "        batch = []\n",
    "        # if self._sort_by_length:\n",
    "            # records = self._iterate_sorted_by_length(limit_max_length=True)\n",
    "        # else:\n",
    "        records = self._iterate_records(limit_max_length=True, shuffle=False)\n",
    "\n",
    "        batch_count = 0\n",
    "\n",
    "        for sent in records:\n",
    "            batch.append(self._encode_for_batch(sent))\n",
    "            if len(batch) >= self._batch_size:\n",
    "                yield self.format_batch(batch)\n",
    "                batch = []\n",
    "                batch_count += 1\n",
    "        if len(batch) > 0:\n",
    "            yield self.format_batch(batch)\n",
    "            batch_count += 1\n",
    "        # yield self.format_batch(batch)\n",
    "\n",
    "        if self._batch_count is None:\n",
    "            self._batch_count = batch_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generate_batches()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self._batch_count is None:\n",
    "            if self._length is None:\n",
    "                self._length = 10000\n",
    "                # for text, annotations in tqdm(self._data, desc=\"Counting entries\"):\n",
    "                #     entry = self._parse_entry(text, annotations)\n",
    "                #     if len(entry.tokens) < self._max_seq_len:\n",
    "                #         self._length += 1\n",
    "\n",
    "            total_valid = self._length\n",
    "            # total_valid = sum(1 for id_, length in self._sent_lenghts.items() if length < self._max_seq_len)\n",
    "            return int(ceil(total_valid / self._batch_size))\n",
    "        else:\n",
    "            return self._batch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(dataset_path, partition):\n",
    "    \"\"\"\n",
    "    Read data storead as JSON records.\n",
    "    \"\"\"\n",
    "    assert partition in {\"train\", \"val\", \"test\"}\n",
    "    data_path = join(dataset_path, f\"var_misuse_seq_{partition}.json\")\n",
    "    \n",
    "    # data = []\n",
    "    for line in open(data_path, \"r\"):\n",
    "        entry = json.loads(line)\n",
    "        \n",
    "        text = entry.pop(\"text\")\n",
    "        yield (text, entry)\n",
    "        # data.append((text, entry))\n",
    "    # return data\n",
    "    \n",
    "def get_num_lines(dataset_path, partition):\n",
    "    assert partition in {\"train\", \"val\", \"test\"}\n",
    "    data_path = join(dataset_path, f\"var_misuse_seq_{partition}.json\")\n",
    "    \n",
    "    return sum(1 for line in open(data_path))\n",
    "\n",
    "    \n",
    "class DataIterator:\n",
    "    def __init__(self, data_path, partition_name):\n",
    "        assert partition_name in {\"train\", \"val\", \"test\"}\n",
    "        \n",
    "        self._data_path = data_path\n",
    "        self._partition_name = partition_name\n",
    "        \n",
    "        self._num_entries = get_num_lines(self._data_path, self._partition_name)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return read_data(self._data_path, self._partition_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._num_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CodebertHybridModelFnClf(nn.Module):\n",
    "    def __init__(\n",
    "            self, codebert_model, graph_emb, padding_idx, num_classes, dense_hidden=100, dropout=0.1, bert_emb_size=768,\n",
    "            no_graph=False\n",
    "    ):\n",
    "        super(CodebertHybridModelFnClf, self).__init__()\n",
    "\n",
    "        self.codebert_model = codebert_model\n",
    "        self.use_graph = not no_graph\n",
    "\n",
    "        num_emb = padding_idx + 1  # padding id is usually not a real embedding\n",
    "\n",
    "        if self.use_graph:\n",
    "            graph_emb_dim = graph_emb.shape[1]\n",
    "            self.graph_emb = nn.Embedding(num_embeddings=num_emb, embedding_dim=graph_emb_dim, padding_idx=padding_idx)\n",
    "\n",
    "            import numpy as np\n",
    "            pretrained_embeddings = torch.from_numpy(np.concatenate([graph_emb, np.zeros((1, graph_emb_dim))], axis=0)).float()\n",
    "            new_param = torch.nn.Parameter(pretrained_embeddings)\n",
    "            assert self.graph_emb.weight.shape == new_param.shape\n",
    "            self.graph_emb.weight = new_param\n",
    "            self.graph_emb.weight.requires_grad = False\n",
    "        else:\n",
    "            graph_emb_dim = 0\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            bert_emb_size + (graph_emb_dim if self.use_graph else 0),\n",
    "            dense_hidden\n",
    "        )\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(dense_hidden, num_classes)\n",
    "\n",
    "        self.loss_f = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, token_ids, graph_ids, mask, finetune=False):\n",
    "        if finetune:\n",
    "            x = self.codebert_model(input_ids=token_ids, attention_mask=mask).pooler_output\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                x = self.codebert_model(input_ids=token_ids, attention_mask=mask).pooler_output\n",
    "\n",
    "#         if self.use_graph:\n",
    "#             graph_emb = self.graph_emb(graph_ids)\n",
    "#             x = torch.cat([x, graph_emb], dim=-1)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, logits, labels, mask, class_weights=None, extra_mask=None):\n",
    "        # if extra_mask is not None:\n",
    "        #     mask = torch.logical_and(mask, extra_mask)\n",
    "        # print(\"logits\", logits.shape)\n",
    "        # print(\"labels\", labels.shape)\n",
    "        # print(\"mask\", mask.shape)\n",
    "        # logits = logits[mask, :]\n",
    "        # labels = labels[mask]\n",
    "        loss = self.loss_f(logits, labels)\n",
    "        # if class_weights is None:\n",
    "        #     loss = tf.reduce_mean(tf.boolean_mask(losses, seq_mask))\n",
    "        # else:\n",
    "        #     loss = tf.reduce_mean(tf.boolean_mask(losses * class_weights, seq_mask))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def score(self, logits, labels, mask, scorer=None, extra_mask=None):\n",
    "        # if extra_mask is not None:\n",
    "            # mask = torch.logical_and(mask, extra_mask)\n",
    "        true_labels = labels\n",
    "        estimated_labels = logits.argmax(-1)\n",
    "\n",
    "        acc = scorer(to_numpy(estimated_labels), to_numpy(true_labels))\n",
    "\n",
    "        return {\"Accuracy\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def batch_to_torch(batch, device):\n",
    "    key_types = {\n",
    "        'tok_ids': torch.LongTensor,\n",
    "        'tags': torch.LongTensor,\n",
    "        'hide_mask': torch.BoolTensor,\n",
    "        'no_loc_mask': torch.BoolTensor,\n",
    "        'lens': torch.LongTensor,\n",
    "        'graph_ids': torch.LongTensor,\n",
    "        'label': torch.LongTensor\n",
    "    }\n",
    "    for key, tf in key_types.items():\n",
    "        if key in batch:\n",
    "            batch[key] = tf(batch[key]).to(device)\n",
    "            \n",
    "\n",
    "def get_length_mask(target, lens):\n",
    "    mask = torch.arange(target.size(1)).to(target.device)[None, :] < lens[:, None]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def train_step_finetune(model, optimizer, token_ids, prefix, suffix, graph_ids, labels, lengths,\n",
    "                   extra_mask=None, class_weights=None, scorer=None, finetune=False, vocab_mapping=None):\n",
    "    token_ids[token_ids == len(vocab_mapping)] = vocab_mapping[\"<unk>\"]\n",
    "    seq_mask = get_length_mask(token_ids, lengths)\n",
    "    logits = model(token_ids, graph_ids, mask=seq_mask, finetune=finetune)\n",
    "    loss = model.loss(logits, labels, mask=seq_mask, class_weights=class_weights, extra_mask=extra_mask)\n",
    "    scores = model.score(logits, labels, mask=seq_mask, scorer=scorer, extra_mask=extra_mask)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    scores[\"Loss\"] = loss.cpu().item()\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def test_step(\n",
    "        model, token_ids, prefix, suffix, graph_ids, labels, lengths, extra_mask=None, class_weights=None, scorer=None,\n",
    "        vocab_mapping=None\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        token_ids[token_ids == len(vocab_mapping)] = vocab_mapping[\"<unk>\"]\n",
    "        seq_mask = get_length_mask(token_ids, lengths)\n",
    "        logits = model(token_ids, graph_ids, mask=seq_mask)\n",
    "        loss = model.loss(logits, labels, mask=seq_mask, class_weights=class_weights, extra_mask=extra_mask)\n",
    "        scores = model.score(logits, labels, mask=seq_mask, scorer=scorer, extra_mask=extra_mask)\n",
    "\n",
    "    scores[\"Loss\"] = loss.cpu().item()\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "class VariableMisuseDetector(CodeBertModelTrainer2):\n",
    "    def set_batcher_class(self):\n",
    "        self.batcher = SimplePythonBatcher\n",
    "    \n",
    "    def get_trial_dir(self):\n",
    "        \"\"\"\n",
    "        Define folder name format for storing checkpoints.\n",
    "        \"\"\"\n",
    "        return os.path.join(self.output_dir, \"codebert_var_mususe_fn_clf\" + str(datetime.now())).replace(\":\", \"-\").replace(\" \", \"_\")\n",
    "    \n",
    "    def train(\n",
    "            self, model, train_batches, test_batches, epochs, report_every=10, scorer=None, learning_rate=0.01,\n",
    "            learning_rate_decay=1., finetune=False, summary_writer=None, save_ckpt_fn=None, no_localization=False\n",
    "    ):\n",
    "        # all training options are specified [here](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/entity/type_prediction.py#L256)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=learning_rate_decay)  # there is no learning rate decay by default\n",
    "\n",
    "        # metric history is stored here\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        # train_f1s = []\n",
    "        # test_f1s = []\n",
    "        \n",
    "\n",
    "        num_train_batches = len(train_batches)\n",
    "        num_test_batches = len(test_batches)\n",
    "\n",
    "        best_acc = 0.\n",
    "\n",
    "        for e in range(epochs):\n",
    "            # losses = []\n",
    "            # ps = []\n",
    "            # rs = []\n",
    "            # f1s = []\n",
    "            train_scores = []\n",
    "            test_scores = []\n",
    "            train_batch_size = []\n",
    "            test_batch_size = []\n",
    "            train_scores_for_averaging = defaultdict(list)\n",
    "            test_scores_for_averaging = defaultdict(list)\n",
    "\n",
    "            start = time()\n",
    "            model.train()\n",
    "\n",
    "            for ind, batch in enumerate(tqdm(train_batches)):\n",
    "                batch_to_torch(batch, self.device)  # inspect the content of `batch`\n",
    "\n",
    "                scores = train_step_finetune(\n",
    "                    model=model, optimizer=optimizer, token_ids=batch['tok_ids'],\n",
    "                    prefix=None, suffix=None, graph_ids=None,  # keep this None\n",
    "                    labels=batch['label'], lengths=batch['lens'],\n",
    "                    extra_mask=None,  # Keep this None\n",
    "                    scorer=scorer,\n",
    "                    finetune=finetune and e / epochs > 0.2,  # finetuning starts after 20% of training is complete\n",
    "                    vocab_mapping=self.vocab_mapping\n",
    "                )\n",
    "                # losses.append(loss)\n",
    "                # ps.append(p)\n",
    "                # rs.append(r)\n",
    "                # f1s.append(f1)\n",
    "                # train_batch_size.append(len(batch['label']))\n",
    "\n",
    "                scores[\"batch_size\"] = len(batch['label'])\n",
    "                for score, value in scores.items():\n",
    "                    self.summary_writer.add_scalar(\n",
    "                        f\"{score}/Train\", value, global_step=e * num_train_batches + ind\n",
    "                    )\n",
    "                    train_scores_for_averaging[score].append(value)\n",
    "                train_scores.append(scores)\n",
    "\n",
    "                # self.summary_writer.add_scalar(\"Loss/Train\", loss, global_step=e * num_train_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"Acc/Train\", p, global_step=e * num_train_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"Recall/Train\", r, global_step=e * num_train_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"F1/Train\", f1, global_step=e * num_train_batches + ind)\n",
    "\n",
    "            # test_alosses = []\n",
    "            # test_aps = []\n",
    "            # test_ars = []\n",
    "            # test_af1s = []\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            for ind, batch in enumerate(test_batches):\n",
    "                batch_to_torch(batch, self.device)\n",
    "                \n",
    "                scores = test_step(\n",
    "                    model=model, token_ids=batch['tok_ids'],\n",
    "                    prefix=None, suffix=None, graph_ids=None,  # keep this None\n",
    "                    labels=batch['label'], lengths=batch['lens'],\n",
    "                    extra_mask=None,  # keep this None\n",
    "                    scorer=scorer, vocab_mapping=self.vocab_mapping\n",
    "                )\n",
    "\n",
    "                scores[\"batch_size\"] = len(batch['label'])\n",
    "                for score, value in scores.items():\n",
    "                    self.summary_writer.add_scalar(\n",
    "                        f\"{score}/Test\", value, global_step=e * num_test_batches + ind\n",
    "                    )\n",
    "                    test_scores_for_averaging[score].append(value)\n",
    "                test_scores.append(scores)\n",
    "                # self.summary_writer.add_scalar(\"Loss/Test\", test_loss, global_step=e * num_test_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"Acc/Test\", test_p, global_step=e * num_test_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"Recall/Test\", test_r, global_step=e * num_test_batches + ind)\n",
    "                # self.summary_writer.add_scalar(\"F1/Test\", test_f1, global_step=e * num_test_batches + ind)\n",
    "                # test_alosses.append(test_loss)\n",
    "                # test_aps.append(test_p)\n",
    "                # test_ars.append(test_r)\n",
    "                # test_af1s.append(test_f1)\n",
    "                # test_batch_size.append(len(batch['label']))\n",
    "\n",
    "            epoch_time = time() - start\n",
    "\n",
    "            # train_losses.append(float(sum(losses) / len(losses)))\n",
    "            # train_f1s.append(float(sum(f1s) / len(f1s)))\n",
    "            # test_losses.append(float(sum(test_alosses) / len(test_alosses)))\n",
    "            # test_f1s.append(float(sum(test_af1s) / len(test_af1s)))\n",
    "\n",
    "            def epoch_wide_acc(scores):\n",
    "                return sum(a * bs for a, bs in zip(scores[\"Accuracy\"], scores[\"batch_size\"])) / sum(scores[\"batch_size\"])\n",
    "\n",
    "            train_acc = epoch_wide_acc(train_scores_for_averaging)\n",
    "            test_acc = epoch_wide_acc(test_scores_for_averaging)\n",
    "            \n",
    "            # train_acc = sum(a * bs for a, bs in zip(ps, train_batch_size)) / sum(train_batch_size)\n",
    "            # test_acc = sum(a * bs for a, bs in zip(test_aps, test_batch_size)) / sum(test_batch_size)\n",
    "\n",
    "\n",
    "            print(f\"Epoch: {e}, {epoch_time: .2f} s\", end=\" \")\n",
    "            for score, value in train_scores_for_averaging.items():\n",
    "                if score == \"batch_size\":\n",
    "                    continue\n",
    "                avg_value = sum(value) / len(value)\n",
    "                print(f\"Train {score}: {avg_value: .4f}\", end=\" \")\n",
    "                self.summary_writer.add_scalar(\n",
    "                    f\"Average {score}/Train\", avg_value, global_step=e\n",
    "                )\n",
    "            for score, value in test_scores_for_averaging.items():\n",
    "                if score == \"batch_size\":\n",
    "                    continue\n",
    "                avg_value = sum(value) / len(value)\n",
    "                print(f\"Test {score}: {avg_value: .4f}\", end=\" \")\n",
    "                self.summary_writer.add_scalar(\n",
    "                    f\"Average {score}/Test\", avg_value, global_step=e\n",
    "                )\n",
    "\n",
    "            print(f\"Epoch Train Acc: {train_acc: .4f}, Epoch Test Acc: {test_acc: .4f}\")\n",
    "\n",
    "            # print(\n",
    "            #     f\"Epoch: {e}, {epoch_time: .2f} s, Train Loss: {train_losses[-1]: .4f}, Train P: {sum(ps) / len(ps): .4f}, Train R: {sum(rs) / len(rs): .4f}, Train F1: {sum(f1s) / len(f1s): .4f}, \"\n",
    "            #     f\"Test loss: {test_losses[-1]: .4f}, Test P: {sum(test_aps) / len(test_aps): .4f}, Test R: {sum(test_ars) / len(test_ars): .4f}, Test F1: {test_f1s[-1]: .4f}\")\n",
    "\n",
    "            if save_ckpt_fn is not None and test_acc > best_acc:\n",
    "                save_ckpt_fn()\n",
    "                best_acc = test_acc\n",
    "\n",
    "            scheduler.step(epoch=e)\n",
    "\n",
    "        return train_scores_for_averaging, test_scores_for_averaging\n",
    "    \n",
    "    def train_model(self, cache_dir=None):\n",
    "        \n",
    "        model_params = copy(self.model_params)\n",
    "\n",
    "        print(f\"\\n\\n{model_params}\")\n",
    "        lr = model_params.pop(\"learning_rate\")\n",
    "        lr_decay = model_params.pop(\"learning_rate_decay\")\n",
    "        suffix_prefix_buckets = model_params.pop(\"suffix_prefix_buckets\")  # used for another model, ignore\n",
    "\n",
    "        print(\"Creating dataloaders\")\n",
    "        train_batcher, test_batcher = self.get_dataloaders(word_emb=None, graph_emb=None, suffix_prefix_buckets=suffix_prefix_buckets, cache_dir=cache_dir)\n",
    "\n",
    "        print(\"Loading pretrained model\")\n",
    "        codebert_model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "        \n",
    "        print(\"Creating model\")\n",
    "        # definition of CodebertHybridModel is at https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/codebert/codebert_train.py#L21\n",
    "        model = CodebertHybridModelFnClf(\n",
    "            codebert_model, graph_emb=None, padding_idx=0, num_classes=train_batcher.num_classes,\n",
    "            no_graph=self.no_graph\n",
    "        )\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            model.cuda()\n",
    "\n",
    "        trial_dir = self.get_trial_dir()  # create directory for saving checkpoints\n",
    "        os.mkdir(trial_dir)\n",
    "        self.create_summary_writer(trial_dir)\n",
    "        \n",
    "        # train_batcher.tagmap.save(os.path.join(trial_dir, \"tagmap.json\"))\n",
    "        # pickle.dump(train_batcher.tagmap, open(os.path.join(trial_dir, \"tag_types.pkl\"), \"wb\"))\n",
    "\n",
    "        def save_ckpt_fn():\n",
    "            checkpoint_path = os.path.join(trial_dir, \"checkpoint\")\n",
    "            torch.save(model, open(checkpoint_path, 'wb'))\n",
    "\n",
    "        print(\"Begin training\")\n",
    "        train_scores, test_scores = self.train(\n",
    "            model=model, train_batches=train_batcher, test_batches=test_batcher,\n",
    "            epochs=self.epochs, learning_rate=lr,\n",
    "            scorer=lambda pred, true: (pred == true).sum() / len(pred),  # need to verify scoring function\n",
    "            learning_rate_decay=lr_decay, finetune=self.finetune, save_ckpt_fn=save_ckpt_fn,\n",
    "            no_localization=self.no_localization\n",
    "        )\n",
    "\n",
    "        metadata = {\n",
    "            \"train_scores\": train_scores,\n",
    "            \"test_scores\": test_scores,\n",
    "            \"learning_rate\": lr,\n",
    "            \"learning_rate_decay\": lr_decay,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"suffix_prefix_buckets\": suffix_prefix_buckets,\n",
    "            \"seq_len\": self.seq_len,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"no_localization\": self.no_localization,\n",
    "        }\n",
    "\n",
    "        # print(\"Maximum accuracy:\", max(test_scores[\"Accuracy\"]))\n",
    "\n",
    "        metadata.update(model_params)\n",
    "\n",
    "        with open(os.path.join(trial_dir, \"params.json\"), \"w\") as metadata_sink:\n",
    "            metadata_sink.write(json.dumps(metadata, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All training options are specified [here](https://github.com/VitalyRomanov/method-embedding/blob/e995477db13a13875cca54c37d4d29f63b0c8e93/SourceCodeTools/nlp/entity/type_prediction.py#L256)\n",
    "Option names are added to `args` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"variable_misuse_graph_2_percent_balanced/with_ast\"\n",
    "\n",
    "args = Namespace()\n",
    "args.__dict__.update({\n",
    "    \"learning_rate\": 1e-6,           #\n",
    "    \"max_seq_len\": 512,              # default for BERT\n",
    "    \"random_seed\": 42,               #\n",
    "    \"epochs\": 30,                     #\n",
    "    \"gpu\": 0,                       # set this to GPU id to use gpu\n",
    "    \"batch_size\": 8,                 # higher value increases memory consumption\n",
    "    \"finetune\": True,  # set this flag to enable finetuning\n",
    "    \"no_localization\": False,        # whether to solve variable misuse with, or without localization\n",
    "    \n",
    "    # do not change items below\n",
    "    \"no_graph\": True,                # used for another model\n",
    "    \"model_output\": dataset_path,    # where to store checkpoints\n",
    "    \"graph_emb_path\": None,          # used for another model\n",
    "    \"word_emb_path\": None,           # used for another model\n",
    "    \"trials\": 1,                     # setting > 1 repeats training, used to accumulate statisitcs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = DataIterator(dataset_path, \"train\")\n",
    "test_data = DataIterator(dataset_path, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data[0]  # ignore `replacements`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = VariableMisuseDetector(\n",
    "    train_data, test_data, params={\"learning_rate\": args.learning_rate, \"learning_rate_decay\": 0.99, \"suffix_prefix_buckets\": 1},\n",
    "    graph_emb_path=args.graph_emb_path, word_emb_path=args.word_emb_path,\n",
    "    output_dir=args.model_output, epochs=args.epochs, batch_size=args.batch_size, gpu_id=args.gpu,\n",
    "    finetune=args.finetune, trials=args.trials, seq_len=args.max_seq_len, no_localization=args.no_localization,\n",
    "    no_graph=args.no_graph\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train_model(cache_dir=Path(dataset_path).joinpath(\"__cache__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- CodeBert ([Huggingface](https://huggingface.co/microsoft/codebert-base))\n",
    "- CodeGPT-2 ([Huggingface](https://huggingface.co/microsoft/CodeGPT-small-py))\n",
    "- GraphCodeBert ([Huggingface](https://huggingface.co/microsoft/graphcodebert-base), [GitHub](https://github.com/microsoft/CodeBERT/tree/master/GraphCodeBERT/refinement))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check example in the script\n",
    "\n",
    "`SourceCodeTools/nlp/entity/utils/visualize_dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SourceCodeTools",
   "language": "python",
   "name": "sourcecodetools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}