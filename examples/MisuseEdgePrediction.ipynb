{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7a6590",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312b007a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "from SourceCodeTools.models.training_config import get_config, save_config, load_config\n",
    "from SourceCodeTools.code.data.dataset.Dataset import SourceGraphDataset, filter_dst_by_freq\n",
    "from SourceCodeTools.models.graph.train.sampling_multitask2 import training_procedure, SamplingMultitaskTrainer\n",
    "from SourceCodeTools.models.graph.train.objectives.NodeClassificationObjective import NodeClassifierObjective\n",
    "from SourceCodeTools.models.graph.train.objectives.SubgraphClassifierObjective import SubgraphAbstractObjective, \\\n",
    "    SubgraphClassifierObjective, SubgraphEmbeddingObjective\n",
    "from SourceCodeTools.models.graph.train.objectives.GraphLinkObjective import SelectiveGraphLinkObjective\n",
    "from SourceCodeTools.models.graph.train.utils import get_name, get_model_base\n",
    "from SourceCodeTools.models.graph import RGGAN\n",
    "from SourceCodeTools.tabular.common import compact_property\n",
    "from SourceCodeTools.code.data.file_utils import unpersist\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e13e0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare parameters and options\n",
    "\n",
    "Full list of options that can be added can be found in `SourceCodeTools/models/training_options.py`. They are ment to be used as arguments for cli trainer. Trainer script can be found in `SourceCodeTools/scripts/train.py`.\n",
    "\n",
    "There are a lot of parameters. Ones that might be of interest are marked with `***`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af522ed3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_path = \"sentencepiece_bpe.model\"\n",
    "\n",
    "data_path = \"variable_misuse_graph_2_percent_misuse_edges\"\n",
    "subgraph_partition = join(data_path, \"partition.json.bz2\")\n",
    "edges_to_predict = join(data_path, \"misuse_edges.json.bz2\")\n",
    "filecontent_path = join(data_path, \"common_filecontent.json.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d81fa442",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = get_config(\n",
    "    # tokenizer\n",
    "    tokenizer_path=\"sentencepiece_bpe.model\", # *** path to sentencepiece model\n",
    "    \n",
    "    # dataset parameters\n",
    "    data_path=data_path,                 # *** path to dataset\n",
    "    use_node_types=False,                # node types currently not supported\n",
    "    use_edge_types=True,                 # whether to use edge types\n",
    "    filter_edges=None,                   # None or list of edge type names\n",
    "    self_loops=False,                    # whether to use self loops\n",
    "    train_frac=0.8,                      # *** fraction of nodes to use for training\n",
    "    random_seed=42,                      # random seed for splitting dataset int o train test validation\n",
    "    min_count_for_objectives=5,          # *** minimum frequency of targets\n",
    "    no_global_edges=False,               # remove global edges\n",
    "    remove_reverse=False,                # remove reverse edges\n",
    "    custom_reverse=None,                 # None or list of edges, for which reverse edges should be created (use together with `remove_reverse`)\n",
    "    \n",
    "    # training parameters\n",
    "    model_output_dir=data_path,      # *** directory to save checkpoints and training data\n",
    "    batch_size=512,                     # *** \n",
    "    sampling_neighbourhood_size=10,      # number of dependencies to sample for each node\n",
    "    neg_sampling_factor=1,               # *** number of negative samples for each positive sample\n",
    "    epochs=10,                           # *** number of epochs\n",
    "    elem_emb_size=100,                   # *** dimensionality of target embeddings (for node name prediction)\n",
    "    pretraining_phase=0,                 # number of epochs for pretraining\n",
    "    embedding_table_size=200000,         # *** embedding table size for subwords\n",
    "    save_checkpoints=False,              # set to False if checkpoints are not needed\n",
    "    save_each_epoch=False,               # save each epoch, useful in case of studying model behavior\n",
    "    measure_scores=False,                 # *** measure ranking scores during evaluation\n",
    "    dilate_scores=200,                   # downsampling factor for measuring scores to make evaluation faster\n",
    "    objectives=\"node_clf\",               # type of objective\n",
    "    force_w2v_ns=True,                   # negative sampling strategy\n",
    "    gpu=-1,                              # gpuid\n",
    "    restore_state=False,\n",
    "    pretrained=None,\n",
    "    \n",
    "    # model parameters\n",
    "    node_emb_size=100,                   # *** dimensionality of node embeddings\n",
    "    h_dim=100,                           # *** should match to node dimensionality\n",
    "    n_layers=3,\n",
    "    num_bases=10,                        # number of bases for computing parmetwer weights for different edge types\n",
    "    dropout=0.2,                         # *** \n",
    "    use_self_loop=True,                  #\n",
    "    activation=\"tanh\",                   # *** \n",
    "    learning_rate=1e-3,                  # *** \n",
    "    use_gcn_checkpoint=True,\n",
    "    use_att_checkpoint=True,\n",
    "    use_gru_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32f966e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save_config(config, \"config_var_misuse_edge_pred.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d4c576",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config = load_config(\"config_var_misuse_edge_pred.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd49c21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': {'data_path': 'variable_misuse_graph_2_percent_misuse_edges',\n",
       "  'train_frac': 0.8,\n",
       "  'filter_edges': None,\n",
       "  'min_count_for_objectives': 5,\n",
       "  'self_loops': False,\n",
       "  'use_node_types': False,\n",
       "  'use_edge_types': True,\n",
       "  'no_global_edges': False,\n",
       "  'remove_reverse': False,\n",
       "  'custom_reverse': None,\n",
       "  'restricted_id_pool': None,\n",
       "  'random_seed': 42,\n",
       "  'subgraph_id_column': 'mentioned_in',\n",
       "  'subgraph_partition': None},\n",
       " 'TRAINING': {'model_output_dir': 'variable_misuse_graph_2_percent_misuse_edges',\n",
       "  'pretrained': None,\n",
       "  'pretraining_phase': 0,\n",
       "  'sampling_neighbourhood_size': 10,\n",
       "  'neg_sampling_factor': 1,\n",
       "  'use_layer_scheduling': False,\n",
       "  'schedule_layers_every': 10,\n",
       "  'elem_emb_size': 100,\n",
       "  'embedding_table_size': 200000,\n",
       "  'epochs': 10,\n",
       "  'batch_size': 512,\n",
       "  'learning_rate': 0.001,\n",
       "  'objectives': 'node_clf',\n",
       "  'save_each_epoch': False,\n",
       "  'save_checkpoints': False,\n",
       "  'early_stopping': False,\n",
       "  'early_stopping_tolerance': 20,\n",
       "  'force_w2v_ns': True,\n",
       "  'use_ns_groups': False,\n",
       "  'nn_index': 'brute',\n",
       "  'metric': 'inner_prod',\n",
       "  'measure_scores': False,\n",
       "  'dilate_scores': 200,\n",
       "  'gpu': -1,\n",
       "  'external_dataset': None,\n",
       "  'restore_state': False},\n",
       " 'MODEL': {'node_emb_size': 100,\n",
       "  'h_dim': 100,\n",
       "  'n_layers': 3,\n",
       "  'use_self_loop': True,\n",
       "  'use_gcn_checkpoint': True,\n",
       "  'use_att_checkpoint': True,\n",
       "  'use_gru_checkpoint': True,\n",
       "  'num_bases': 10,\n",
       "  'dropout': 0.2,\n",
       "  'activation': 'tanh'},\n",
       " 'TOKENIZER': {'tokenizer_path': 'sentencepiece_bpe.model'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bd4ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87b0b0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Random state for splitting dataset is fixed\n"
     ]
    }
   ],
   "source": [
    "dataset = SourceGraphDataset(\n",
    "    **{**config[\"DATASET\"], **config[\"TOKENIZER\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f2a40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Declare target loading function (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32323440",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_edge_prediction():\n",
    "    from SourceCodeTools.code.data.dataset.reader import load_data\n",
    "    \n",
    "    nodes, edges = dataset.nodes, dataset.edges\n",
    "    \n",
    "    mentions = set(dataset.nodes.query(\"type_backup == 'mention'\")[\"id\"])  # only mentions\n",
    "    elements = dataset.edges.query(\"src.map(@is_mention)\", local_dict={\"is_mention\": lambda x: x in mentions})\n",
    "    \n",
    "    type_ann = unpersist(edges_to_predict)\n",
    "    type_ann = type_ann[[\"src\", \"dst\"]]\n",
    "\n",
    "    return elements, type_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437af5a9-8da3-47b3-acc4-6b6172a6eea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            id                type     src     dst  file_id  mentioned_in  \\\n",
       " 1            1                arg_  238713   16185    75721        248998   \n",
       " 8            8                arg_   18043   20305    75721        248998   \n",
       " 15          15              value_   41771  212093    75721        248998   \n",
       " 23          25               args_   18043  193152    75721        248998   \n",
       " 36          40            targets_  103431  214680    75721        248998   \n",
       " ...        ...                 ...     ...     ...      ...           ...   \n",
       " 870516  965434              value_   49653   95549   556471         91076   \n",
       " 870521  965439              value_  125993   75887   556471         91076   \n",
       " 870523  965441              lower_  223139   66077   556471         91076   \n",
       " 870548  965467               args_   49653  260354   556471         91076   \n",
       " 870562  965481  function_name_rev_  236850   91076   556471         16446   \n",
       " \n",
       "         offset_start  offset_end         type_backup  \n",
       " 1                NaN         NaN                arg_  \n",
       " 8                NaN         NaN                arg_  \n",
       " 15              53.0        59.0              value_  \n",
       " 23              76.0        90.0               args_  \n",
       " 36              40.0        50.0            targets_  \n",
       " ...              ...         ...                 ...  \n",
       " 870516         277.0       281.0              value_  \n",
       " 870521         289.0       299.0              value_  \n",
       " 870523         300.0       301.0              lower_  \n",
       " 870548         343.0       347.0               args_  \n",
       " 870562           NaN         NaN  function_name_rev_  \n",
       " \n",
       " [125682 rows x 9 columns],\n",
       "          src     dst\n",
       " 0     103431   42742\n",
       " 1      60434   57118\n",
       " 2     121179  104211\n",
       " 3     180808  268065\n",
       " 4     142647  218764\n",
       " ...      ...     ...\n",
       " 5608  175993   88220\n",
       " 5609  129356   47702\n",
       " 5610  250001  114541\n",
       " 5611   12201  147130\n",
       " 5612   49653   12028\n",
       " \n",
       " [5613 rows x 2 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_edge_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a2158",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90c861",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![](\"examples/figures/img1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379314c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One or several objectives could be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed5c13c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(SamplingMultitaskTrainer):\n",
    "    def create_objectives(self, dataset, tokenizer_path):\n",
    "        self.objectives = nn.ModuleList()\n",
    "        self.objectives.append(\n",
    "            SelectiveGraphLinkObjective(\n",
    "                \"VarMisuseEdgePred\",\n",
    "                self.graph_model, self.node_embedder, dataset.nodes,\n",
    "                load_edge_prediction,                                                   # need to define this function\n",
    "                self.device, self.sampling_neighbourhood_size, self.batch_size,\n",
    "                tokenizer_path=tokenizer_path, target_emb_size=self.elem_emb_size, \n",
    "                masker=None,                                                            # masker is not needed here\n",
    "                measure_scores=self.trainer_params[\"measure_scores\"],\n",
    "                dilate_scores=self.trainer_params[\"dilate_scores\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d37c68d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"large_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b08068ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes 269370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████| 9/9 [01:17<00:00,  8.66s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.09s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.95s/it]\n",
      "Epoch 1:   0%|                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Time: 86 s\n",
      "{'Accuracy/test/VarMisuseEdgePred_': 0.5568549923780488,\n",
      " 'Accuracy/train/VarMisuseEdgePred_': 0.51775956284153,\n",
      " 'Accuracy/train_avg/VarMisuseEdgePred': 0.5045774514268366,\n",
      " 'Accuracy/val/VarMisuseEdgePred_': 0.5665992914244187,\n",
      " 'Loss/test/VarMisuseEdgePred_': 0.49005594849586487,\n",
      " 'Loss/train/VarMisuseEdgePred_': 0.5391011834144592,\n",
      " 'Loss/train_avg/VarMisuseEdgePred': 0.5667653944757249,\n",
      " 'Loss/val/VarMisuseEdgePred_': 0.48405277729034424}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|████                                | 1/9 [00:11<01:34, 11.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_procedure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRGGAN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRAINING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_base_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_model_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRAINING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRGGAN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTOKENIZER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizer_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrainer\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/sampling_multitask2.py:825\u001b[0m, in \u001b[0;36mtraining_procedure\u001b[0;34m(dataset, model_name, model_params, trainer_params, model_base_path, tokenizer_path, trainer, load_external_dataset)\u001b[0m\n\u001b[1;32m    812\u001b[0m trainer \u001b[38;5;241m=\u001b[39m trainer(\n\u001b[1;32m    813\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    814\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m     load_external_dataset\u001b[38;5;241m=\u001b[39mload_external_dataset\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# except KeyboardInterrupt:\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m#     logging.info(\"Training interrupted\")\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# except EarlyStopping:\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m#     logging.info(\"Early stopping triggered\")\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m#     print(\"There was an exception\", e)\u001b[39;00m\n\u001b[1;32m    833\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/sampling_multitask2.py:547\u001b[0m, in \u001b[0;36mSamplingMultitaskTrainer.train_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_sampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw2v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforce_w2v_ns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjectives)  \u001b[38;5;66;03m# assumes the same batch size for all objectives\u001b[39;00m\n\u001b[1;32m    553\u001b[0m loss_accum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/objectives/AbstractObjective.py:586\u001b[0m, in \u001b[0;36mAbstractObjective.forward\u001b[0;34m(self, input_nodes, seeds, blocks, train_embeddings, neg_sampling_strategy)\u001b[0m\n\u001b[1;32m    584\u001b[0m masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker\u001b[38;5;241m.\u001b[39mget_mask(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseeds_to_python(seeds)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    585\u001b[0m graph_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_embeddings(input_nodes, blocks, train_embeddings, masked\u001b[38;5;241m=\u001b[39mmasked)\n\u001b[0;32m--> 586\u001b[0m node_embs_, element_embs_, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_for_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_embedding_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_sampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_sampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_embeddings\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m acc, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_acc_loss(node_embs_, element_embs_, labels)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/objectives/AbstractObjective.py:490\u001b[0m, in \u001b[0;36mAbstractObjective.prepare_for_prediction\u001b[0;34m(self, node_embeddings, seeds, target_embedding_fn, negative_factor, neg_sampling_strategy, train_embeddings)\u001b[0m\n\u001b[1;32m    485\u001b[0m positive_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_embedder[indices]\n\u001b[1;32m    486\u001b[0m negative_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_negative(\n\u001b[1;32m    487\u001b[0m     k\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m k, ids\u001b[38;5;241m=\u001b[39mindices, neg_sampling_strategy\u001b[38;5;241m=\u001b[39mneg_sampling_strategy\n\u001b[1;32m    488\u001b[0m )\n\u001b[0;32m--> 490\u001b[0m positive_dst, negative_dst \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_embedding_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# TODO breaks cache in\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m#  SourceCodeTools.models.graph.train.objectives.GraphLinkClassificationObjective.TargetLinkMapper.get_labels\u001b[39;00m\n\u001b[1;32m    496\u001b[0m labels_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_positive_labels(indices)\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/objectives/AbstractObjective.py:441\u001b[0m, in \u001b[0;36mAbstractObjective.get_targets_from_nodes\u001b[0;34m(self, positive_indices, negative_indices, train_embeddings)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst_embeddings\n\u001b[1;32m    440\u001b[0m positive_dst \u001b[38;5;241m=\u001b[39m get_embeddings_for_targets(positive_indices)\n\u001b[0;32m--> 441\u001b[0m negative_dst \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings_for_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative_indices\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m negative_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m positive_dst, negative_dst\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/objectives/AbstractObjective.py:431\u001b[0m, in \u001b[0;36mAbstractObjective.get_targets_from_nodes.<locals>.get_embeddings_for_targets\u001b[0;34m(dst)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dst_seeds\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m unique_dst\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dst_seeds\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m==\u001b[39m unique_dst\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 431\u001b[0m unique_dst_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use_types, ntypes)\u001b[39;00m\n\u001b[1;32m    432\u001b[0m dst_embeddings \u001b[38;5;241m=\u001b[39m unique_dst_embeddings[slice_map\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)]\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_embeddings_for_queries:\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/train/objectives/AbstractObjective.py:377\u001b[0m, in \u001b[0;36mAbstractObjective._graph_embeddings\u001b[0;34m(self, input_nodes, blocks, train_embeddings, masked)\u001b[0m\n\u001b[1;32m    374\u001b[0m         emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_embedder(node_ids\u001b[38;5;241m=\u001b[39minput_nodes, train_embeddings\u001b[38;5;241m=\u001b[39mtrain_embeddings, masked\u001b[38;5;241m=\u001b[39mmasked)\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# emb = self.graph_model.node_embed()[input_nodes]\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_types:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ntype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_model\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39mntypes:\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/rgcn_sampling.py:341\u001b[0m, in \u001b[0;36mRGCNSampling.forward\u001b[0;34m(self, h, blocks, return_all)\u001b[0m\n\u001b[1;32m    338\u001b[0m h0 \u001b[38;5;241m=\u001b[39m h\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, norm, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm, blocks):\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# h = checkpoint.checkpoint(self.custom(layer), block, h)\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(h, norm)\n\u001b[1;32m    343\u001b[0m     all_layers\u001b[38;5;241m.\u001b[39mappend(h) \u001b[38;5;66;03m# added this as an experimental feature for intermediate supervision\u001b[39;00m\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/method-embeddings/SourceCodeTools/models/graph/rggan.py:276\u001b[0m, in \u001b[0;36mRGGANLayer.forward\u001b[0;34m(self, g, inputs, h0)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     inputs_src \u001b[38;5;241m=\u001b[39m inputs_dst \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 276\u001b[0m hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwdict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(ntype, h):\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_loop:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;66;03m# h = h + th.matmul(inputs_dst[ntype], self_loop_wdict[ntype])\u001b[39;00m\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/dgl/nn/pytorch/hetero.py:171\u001b[0m, in \u001b[0;36mHeteroGraphConv.forward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     dst_inputs \u001b[38;5;241m=\u001b[39m {k: v[:g\u001b[38;5;241m.\u001b[39mnumber_of_dst_nodes(k)] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stype, etype, dtype \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mcanonical_etypes:\n\u001b[0;32m--> 171\u001b[0m     rel_graph \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rel_graph\u001b[38;5;241m.\u001b[39mnumber_of_edges() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/dgl/heterograph.py:2228\u001b[0m, in \u001b[0;36mDGLHeteroGraph.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(err_msg)\n\u001b[0;32m-> 2228\u001b[0m etypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_etypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(etypes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid key \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Must be one of the edge types.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(orig_key))\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/dgl/heterograph.py:2131\u001b[0m, in \u001b[0;36mDGLHeteroGraph._find_etypes\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_etypes\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 2131\u001b[0m     etypes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2132\u001b[0m         i \u001b[38;5;28;01mfor\u001b[39;00m i, (srctype, etype, dsttype) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_canonical_etypes) \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m   2133\u001b[0m         (key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m srctype) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2134\u001b[0m         (key[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m etype) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2135\u001b[0m         (key[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m dsttype)]\n\u001b[1;32m   2136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m etypes\n",
      "File \u001b[0;32m~/Soft/miniconda3/envs/SourceCodeTools/lib/python3.8/site-packages/dgl/heterograph.py:2131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_etypes\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 2131\u001b[0m     etypes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2132\u001b[0m         i \u001b[38;5;28;01mfor\u001b[39;00m i, (srctype, etype, dsttype) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_canonical_etypes) \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m   2133\u001b[0m         (key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m srctype) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2134\u001b[0m         (key[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m etype) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2135\u001b[0m         (key[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m SLICE_FULL \u001b[38;5;129;01mor\u001b[39;00m key[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m dsttype)]\n\u001b[1;32m   2136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m etypes\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_procedure(\n",
    "    dataset, \n",
    "    model_name=RGGAN, \n",
    "    model_params=config[\"MODEL\"],\n",
    "    trainer_params=config[\"TRAINING\"],\n",
    "    model_base_path=get_model_base(config[\"TRAINING\"], get_name(RGGAN, str(datetime.now()))),\n",
    "    tokenizer_path=config[\"TOKENIZER\"][\"tokenizer_path\"],\n",
    "    trainer=Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadb752",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db131dea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SourceCodeTools]",
   "language": "python",
   "name": "conda-env-SourceCodeTools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
