{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7a6590",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312b007a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "from SourceCodeTools.models.training_config import get_config, save_config, load_config\n",
    "from SourceCodeTools.code.data.dataset.Dataset import SourceGraphDataset, filter_dst_by_freq\n",
    "from SourceCodeTools.models.graph.train.sampling_multitask2 import training_procedure, SamplingMultitaskTrainer\n",
    "from SourceCodeTools.models.graph.train.objectives.NodeClassificationObjective import NodeClassifierObjective\n",
    "from SourceCodeTools.models.graph.train.objectives.SubgraphClassifierObjective import SubgraphAbstractObjective, \\\n",
    "    SubgraphClassifierObjective, SubgraphEmbeddingObjective\n",
    "from SourceCodeTools.models.graph.train.utils import get_name, get_model_base\n",
    "from SourceCodeTools.models.graph import RGGAN\n",
    "from SourceCodeTools.tabular.common import compact_property\n",
    "from SourceCodeTools.code.data.file_utils import unpersist\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e13e0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare parameters and options\n",
    "\n",
    "Full list of options that can be added can be found in `SourceCodeTools/models/training_options.py`. They are ment to be used as arguments for cli trainer. Trainer script can be found in `SourceCodeTools/scripts/train.py`.\n",
    "\n",
    "There are a lot of parameters. Ones that might be of interest are marked with `***`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af522ed3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_path = \"sentencepiece_bpe.model\"\n",
    "\n",
    "data_path = \"variable_misuse_graph_2_percent_misuse_edges\"\n",
    "subgraph_partition = join(data_path, \"partition.json.bz2\")\n",
    "edges_to_predict = join(data_path, \"misuse_edges.json.bz2\")\n",
    "filecontent_path = join(data_path, \"common_filecontent.json.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81fa442",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = get_config(\n",
    "    # tokenizer\n",
    "    tokenizer_path=\"sentencepiece_bpe.model\", # *** path to sentencepiece model\n",
    "    \n",
    "    # dataset parameters\n",
    "    data_path=data_path,                 # *** path to dataset\n",
    "    use_node_types=False,                # node types currently not supported\n",
    "    use_edge_types=True,                 # whether to use edge types\n",
    "    filter_edges=None,                   # None or list of edge type names\n",
    "    self_loops=False,                    # whether to use self loops\n",
    "    train_frac=0.8,                      # *** fraction of nodes to use for training\n",
    "    random_seed=42,                      # random seed for splitting dataset int o train test validation\n",
    "    min_count_for_objectives=5,          # *** minimum frequency of targets\n",
    "    no_global_edges=False,               # remove global edges\n",
    "    remove_reverse=False,                # remove reverse edges\n",
    "    custom_reverse=None,                 # None or list of edges, for which reverse edges should be created (use together with `remove_reverse`)\n",
    "    \n",
    "    # training parameters\n",
    "    model_output_dir=data_path,      # *** directory to save checkpoints and training data\n",
    "    batch_size=128,                     # *** \n",
    "    sampling_neighbourhood_size=10,      # number of dependencies to sample for each node\n",
    "    neg_sampling_factor=1,               # *** number of negative samples for each positive sample\n",
    "    epochs=10,                           # *** number of epochs\n",
    "    elem_emb_size=100,                   # *** dimensionality of target embeddings (for node name prediction)\n",
    "    pretraining_phase=0,                 # number of epochs for pretraining\n",
    "    embedding_table_size=200000,         # *** embedding table size for subwords\n",
    "    save_checkpoints=False,              # set to False if checkpoints are not needed\n",
    "    save_each_epoch=False,               # save each epoch, useful in case of studying model behavior\n",
    "    measure_scores=True,                 # *** measure ranking scores during evaluation\n",
    "    dilate_scores=200,                   # downsampling factor for measuring scores to make evaluation faster\n",
    "    objectives=\"node_clf\",               # type of objective\n",
    "    force_w2v_ns=True,                   # negative sampling strategy\n",
    "    gpu=-1,                              # gpuid\n",
    "    restore_state=False,\n",
    "    pretrained=None,\n",
    "    \n",
    "    # model parameters\n",
    "    node_emb_size=100,                   # *** dimensionality of node embeddings\n",
    "    h_dim=100,                           # *** should match to node dimensionality\n",
    "    num_bases=10,                        # number of bases for computing parmetwer weights for different edge types\n",
    "    dropout=0.2,                         # *** \n",
    "    use_self_loop=True,                  #\n",
    "    activation=\"tanh\",                   # *** \n",
    "    learning_rate=1e-3,                  # *** \n",
    "    use_gcn_checkpoint=True,\n",
    "    use_att_checkpoint=True,\n",
    "    use_gru_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32f966e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save_config(config, \"config_var_misuse_edge_pred.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d4c576",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config = load_config(\"config_var_misuse_edge_pred.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd49c21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': {'data_path': 'variable_misuse_graph_2_percent_misuse_edges',\n",
       "  'train_frac': 0.8,\n",
       "  'filter_edges': None,\n",
       "  'min_count_for_objectives': 5,\n",
       "  'self_loops': False,\n",
       "  'use_node_types': False,\n",
       "  'use_edge_types': True,\n",
       "  'no_global_edges': False,\n",
       "  'remove_reverse': False,\n",
       "  'custom_reverse': None,\n",
       "  'restricted_id_pool': None,\n",
       "  'random_seed': 42,\n",
       "  'subgraph_id_column': 'mentioned_in',\n",
       "  'subgraph_partition': None},\n",
       " 'TRAINING': {'model_output_dir': 'variable_misuse_graph_2_percent_misuse_edges',\n",
       "  'pretrained': None,\n",
       "  'pretraining_phase': 0,\n",
       "  'sampling_neighbourhood_size': 10,\n",
       "  'neg_sampling_factor': 1,\n",
       "  'use_layer_scheduling': False,\n",
       "  'schedule_layers_every': 10,\n",
       "  'elem_emb_size': 100,\n",
       "  'embedding_table_size': 200000,\n",
       "  'epochs': 10,\n",
       "  'batch_size': 128,\n",
       "  'learning_rate': 0.001,\n",
       "  'objectives': 'node_clf',\n",
       "  'save_each_epoch': False,\n",
       "  'save_checkpoints': False,\n",
       "  'early_stopping': False,\n",
       "  'early_stopping_tolerance': 20,\n",
       "  'force_w2v_ns': True,\n",
       "  'use_ns_groups': False,\n",
       "  'nn_index': 'brute',\n",
       "  'metric': 'inner_prod',\n",
       "  'measure_scores': True,\n",
       "  'dilate_scores': 200,\n",
       "  'gpu': -1,\n",
       "  'external_dataset': None,\n",
       "  'restore_state': False},\n",
       " 'MODEL': {'node_emb_size': 100,\n",
       "  'h_dim': 100,\n",
       "  'n_layers': 5,\n",
       "  'use_self_loop': True,\n",
       "  'use_gcn_checkpoint': True,\n",
       "  'use_att_checkpoint': True,\n",
       "  'use_gru_checkpoint': True,\n",
       "  'num_bases': 10,\n",
       "  'dropout': 0.2,\n",
       "  'activation': 'tanh'},\n",
       " 'TOKENIZER': {'tokenizer_path': 'sentencepiece_bpe.model'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bd4ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d87b0b0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Random state for splitting dataset is fixed\n"
     ]
    }
   ],
   "source": [
    "dataset = SourceGraphDataset(\n",
    "    **{**config[\"DATASET\"], **config[\"TOKENIZER\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f2a40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Declare target loading function (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32323440",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_edge_prediction():\n",
    "    from SourceCodeTools.code.data.dataset.reader import load_data\n",
    "    \n",
    "    nodes, edges = dataset.nodes, dataset.edges\n",
    "    \n",
    "    type_ann = unpersist(edges_to_predict)\n",
    "    type_ann = type_ann[[\"src\", \"dst\"]]\n",
    "\n",
    "    return type_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437af5a9-8da3-47b3-acc4-6b6172a6eea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103431</td>\n",
       "      <td>42742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60434</td>\n",
       "      <td>57118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121179</td>\n",
       "      <td>104211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180808</td>\n",
       "      <td>268065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142647</td>\n",
       "      <td>218764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>175993</td>\n",
       "      <td>88220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>129356</td>\n",
       "      <td>47702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>250001</td>\n",
       "      <td>114541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>12201</td>\n",
       "      <td>147130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>49653</td>\n",
       "      <td>12028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         src     dst\n",
       "0     103431   42742\n",
       "1      60434   57118\n",
       "2     121179  104211\n",
       "3     180808  268065\n",
       "4     142647  218764\n",
       "...      ...     ...\n",
       "5608  175993   88220\n",
       "5609  129356   47702\n",
       "5610  250001  114541\n",
       "5611   12201  147130\n",
       "5612   49653   12028\n",
       "\n",
       "[5613 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_edge_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a2158",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define objectives\n",
    "\n",
    "Currenlty objectives for node classification (`EdgePrediction`), and name-based node embedding training `SubwordEmbedderObjective`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90c861",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![](\"examples/figures/img1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379314c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One or several objectives could be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed5c13c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from SourceCodeTools.models.graph.train.objectives.GraphLinkObjective import GraphLinkObjective\n",
    "\n",
    "class Trainer(SamplingMultitaskTrainer):\n",
    "    def create_objectives(self, dataset, tokenizer_path):\n",
    "        self.objectives = nn.ModuleList()\n",
    "        self.objectives.append(\n",
    "            GraphLinkObjective(\n",
    "                \"VarMisuseEdgePred\",\n",
    "                self.graph_model, self.node_embedder, dataset.nodes,\n",
    "                load_edge_prediction,                                                   # need to define this function\n",
    "                self.device, self.sampling_neighbourhood_size, self.batch_size,\n",
    "                tokenizer_path=tokenizer_path, target_emb_size=self.elem_emb_size, \n",
    "                masker=None,                                                            # masker is not needed here\n",
    "                measure_scores=self.trainer_params[\"measure_scores\"],\n",
    "                dilate_scores=self.trainer_params[\"dilate_scores\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d37c68d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"large_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b08068ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_procedure(\n",
    "#     dataset, \n",
    "#     model_name=RGGAN, \n",
    "#     model_params=config[\"MODEL\"],\n",
    "#     trainer_params=config[\"TRAINING\"],\n",
    "#     model_base_path=get_model_base(config[\"TRAINING\"], get_name(RGGAN, str(datetime.now()))),\n",
    "#     tokenizer_path=config[\"TOKENIZER\"][\"tokenizer_path\"],\n",
    "#     trainer=Trainer\n",
    "# )\n",
    "\n",
    "# target is currently sampled incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadb752",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db131dea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SourceCodeTools]",
   "language": "python",
   "name": "conda-env-SourceCodeTools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
